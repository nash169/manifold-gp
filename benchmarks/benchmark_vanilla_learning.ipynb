{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e276dbe",
   "metadata": {},
   "source": [
    "# Vanilla GP Supervised Learning via Precision Matrix on 1D Manifold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36444a5",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d17d1f",
   "metadata": {},
   "source": [
    "This notebook provides an example of how to perform Gaussian Process Regression on a 1D manifold. In this example we consider a supervised learning scenario, namely the number of labeled data points is equivalent to the number of the sampled points from the underlying manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e9afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import scipy.spatial as ss\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "from time import time\n",
    "\n",
    "from manifold_gp.models.vanilla_gp import VanillaGP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75701656",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02483bf0",
   "metadata": {},
   "source": [
    "### Load & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af216c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mnist' # ['protein','elevators', 'ctslice', 'mnist']\n",
    "cut = 10000\n",
    "\n",
    "if dataset == 'protein':\n",
    "    data = np.loadtxt('datasets/protein.csv', delimiter=\",\")[:cut]\n",
    "    sampled_x, sampled_y = data[:, 1:], data[:, 0]\n",
    "elif dataset == 'elevators':\n",
    "    data = np.array(loadmat('datasets/elevators.mat')['data'])\n",
    "    sampled_x, sampled_y = data[:, :-1], data[:, -1]\n",
    "elif dataset == 'ctslice':\n",
    "    data = np.loadtxt('datasets/ctslice.csv', delimiter=\",\")[:cut]\n",
    "    sampled_x, sampled_y = data[:, :-1], data[:, -1]\n",
    "elif dataset == 'mnist':\n",
    "    data = np.loadtxt('datasets/mnist.csv')\n",
    "    sampled_x, sampled_y = data[:, 2:], data[:, 1]\n",
    "    torch.manual_seed(1337)\n",
    "    rand_idx = torch.randperm(sampled_x.shape[0])\n",
    "    sampled_x = sampled_x[rand_idx]\n",
    "    sampled_y = sampled_y[rand_idx]\n",
    "    \n",
    "preprocess = False\n",
    "normalize_features = False\n",
    "normalize_labels = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19b314d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preprocess:\n",
    "    # remove coincident points\n",
    "    sampled_x, id_unique = np.unique(sampled_x, axis=0, return_index=True)\n",
    "    sampled_y = sampled_y[id_unique]\n",
    "\n",
    "    # cut between 0.01 and 0.99 quantile of distances\n",
    "    kd_tree = ss.KDTree(sampled_x)\n",
    "    v = kd_tree.query(sampled_x, k=2)[0][:, 1]\n",
    "    idx = np.argsort(v)\n",
    "    percentile_start = int(np.round(idx.shape[0]*0.10))\n",
    "    percentile_end = int(np.round(idx.shape[0]*0.90))\n",
    "    sampled_x = sampled_x[idx[percentile_start:percentile_end], :]\n",
    "    sampled_y = sampled_y[idx[percentile_start:percentile_end]]\n",
    "m = sampled_x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331daec5",
   "metadata": {},
   "source": [
    "### Trainset & Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163309fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.2 * m)\n",
    "\n",
    "train_x, train_y = sampled_x[:split], sampled_y[:split]\n",
    "test_x, test_y = sampled_x[split:], sampled_y[split:]\n",
    "\n",
    "train_x = torch.from_numpy(train_x).float()\n",
    "train_y = torch.from_numpy(train_y).float()\n",
    "test_x = torch.from_numpy(test_x).float()\n",
    "test_y = torch.from_numpy(test_y).float()\n",
    "\n",
    "if normalize_features:\n",
    "    mu_x, std_x = train_x.mean(dim=-2, keepdim=True), train_x.std(dim=-2, keepdim=True) + 1e-6\n",
    "    train_x.sub_(mu_x).div_(std_x)\n",
    "    test_x.sub_(mu_x).div_(std_x)\n",
    "    \n",
    "if normalize_labels:\n",
    "    mu_y, std_y = train_y.mean(), train_y.std()\n",
    "    train_y.sub_(mu_y).div_(std_y)\n",
    "    test_y.sub_(mu_y).div_(std_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87581de",
   "metadata": {},
   "source": [
    "### Move Data to Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c91b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "train_x, train_y = train_x.to(device), train_y.to(device)\n",
    "test_x, test_y = test_x.to(device), test_y.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3441ad2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15e47b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(\n",
    "    noise_constraint=gpytorch.constraints.GreaterThan(1e-8),\n",
    "    noise_prior=None  # NormalPrior(torch.tensor([0.0]).to(device),  torch.tensor([1/9]).sqrt().to(device))\n",
    ")\n",
    "\n",
    "kernel = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=2.5))\n",
    "# gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "model = VanillaGP(train_x, train_y, likelihood, kernel).to(device)\n",
    "\n",
    "hypers = {\n",
    "    'likelihood.noise_covar.noise': 1e-2,\n",
    "    'covar_module.base_kernel.lengthscale': 0.5,\n",
    "    'covar_module.outputscale': 1.0,\n",
    "}\n",
    "model.initialize(**hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14763b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb0ab30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: -0.673, Noise Variance: 0.100, Signal Variance: 1.000, Lengthscale: 0.500\n",
      "Iteration: 1, Loss: -0.677, Noise Variance: 0.100, Signal Variance: 0.997, Lengthscale: 0.504\n",
      "Iteration: 2, Loss: -0.688, Noise Variance: 0.099, Signal Variance: 0.994, Lengthscale: 0.508\n",
      "Iteration: 3, Loss: -0.690, Noise Variance: 0.099, Signal Variance: 0.991, Lengthscale: 0.512\n",
      "Iteration: 4, Loss: -0.705, Noise Variance: 0.098, Signal Variance: 0.987, Lengthscale: 0.516\n",
      "Iteration: 5, Loss: -0.706, Noise Variance: 0.098, Signal Variance: 0.984, Lengthscale: 0.520\n",
      "Iteration: 6, Loss: -0.718, Noise Variance: 0.097, Signal Variance: 0.981, Lengthscale: 0.524\n",
      "Iteration: 7, Loss: -0.719, Noise Variance: 0.097, Signal Variance: 0.978, Lengthscale: 0.528\n",
      "Iteration: 8, Loss: -0.731, Noise Variance: 0.096, Signal Variance: 0.975, Lengthscale: 0.532\n",
      "Iteration: 9, Loss: -0.727, Noise Variance: 0.096, Signal Variance: 0.972, Lengthscale: 0.536\n",
      "Iteration: 10, Loss: -0.745, Noise Variance: 0.095, Signal Variance: 0.969, Lengthscale: 0.540\n",
      "Iteration: 11, Loss: -0.746, Noise Variance: 0.095, Signal Variance: 0.965, Lengthscale: 0.545\n",
      "Iteration: 12, Loss: -0.760, Noise Variance: 0.094, Signal Variance: 0.962, Lengthscale: 0.549\n",
      "Iteration: 13, Loss: -0.776, Noise Variance: 0.094, Signal Variance: 0.959, Lengthscale: 0.553\n",
      "Iteration: 14, Loss: -0.781, Noise Variance: 0.093, Signal Variance: 0.956, Lengthscale: 0.557\n",
      "Iteration: 15, Loss: -0.781, Noise Variance: 0.093, Signal Variance: 0.953, Lengthscale: 0.561\n",
      "Iteration: 16, Loss: -0.785, Noise Variance: 0.092, Signal Variance: 0.950, Lengthscale: 0.566\n",
      "Iteration: 17, Loss: -0.787, Noise Variance: 0.092, Signal Variance: 0.947, Lengthscale: 0.570\n",
      "Iteration: 18, Loss: -0.803, Noise Variance: 0.091, Signal Variance: 0.944, Lengthscale: 0.574\n",
      "Iteration: 19, Loss: -0.809, Noise Variance: 0.091, Signal Variance: 0.940, Lengthscale: 0.579\n",
      "Iteration: 20, Loss: -0.820, Noise Variance: 0.090, Signal Variance: 0.937, Lengthscale: 0.583\n",
      "Iteration: 21, Loss: -0.819, Noise Variance: 0.090, Signal Variance: 0.934, Lengthscale: 0.587\n",
      "Iteration: 22, Loss: -0.827, Noise Variance: 0.090, Signal Variance: 0.931, Lengthscale: 0.592\n",
      "Iteration: 23, Loss: -0.832, Noise Variance: 0.089, Signal Variance: 0.928, Lengthscale: 0.596\n",
      "Iteration: 24, Loss: -0.834, Noise Variance: 0.089, Signal Variance: 0.925, Lengthscale: 0.601\n",
      "Iteration: 25, Loss: -0.845, Noise Variance: 0.088, Signal Variance: 0.922, Lengthscale: 0.605\n",
      "Iteration: 26, Loss: -0.862, Noise Variance: 0.088, Signal Variance: 0.919, Lengthscale: 0.609\n",
      "Iteration: 27, Loss: -0.870, Noise Variance: 0.087, Signal Variance: 0.916, Lengthscale: 0.614\n",
      "Iteration: 28, Loss: -0.880, Noise Variance: 0.087, Signal Variance: 0.913, Lengthscale: 0.618\n",
      "Iteration: 29, Loss: -0.883, Noise Variance: 0.086, Signal Variance: 0.910, Lengthscale: 0.623\n",
      "Iteration: 30, Loss: -0.901, Noise Variance: 0.086, Signal Variance: 0.907, Lengthscale: 0.627\n",
      "Iteration: 31, Loss: -0.890, Noise Variance: 0.086, Signal Variance: 0.904, Lengthscale: 0.632\n",
      "Iteration: 32, Loss: -0.899, Noise Variance: 0.085, Signal Variance: 0.901, Lengthscale: 0.636\n",
      "Iteration: 33, Loss: -0.904, Noise Variance: 0.085, Signal Variance: 0.898, Lengthscale: 0.641\n",
      "Iteration: 34, Loss: -0.910, Noise Variance: 0.084, Signal Variance: 0.895, Lengthscale: 0.646\n",
      "Iteration: 35, Loss: -0.922, Noise Variance: 0.084, Signal Variance: 0.892, Lengthscale: 0.650\n",
      "Iteration: 36, Loss: -0.931, Noise Variance: 0.083, Signal Variance: 0.888, Lengthscale: 0.655\n",
      "Iteration: 37, Loss: -0.942, Noise Variance: 0.083, Signal Variance: 0.885, Lengthscale: 0.660\n",
      "Iteration: 38, Loss: -0.943, Noise Variance: 0.083, Signal Variance: 0.882, Lengthscale: 0.664\n",
      "Iteration: 39, Loss: -0.946, Noise Variance: 0.082, Signal Variance: 0.879, Lengthscale: 0.669\n",
      "Iteration: 40, Loss: -0.957, Noise Variance: 0.082, Signal Variance: 0.876, Lengthscale: 0.674\n",
      "Iteration: 41, Loss: -0.961, Noise Variance: 0.081, Signal Variance: 0.873, Lengthscale: 0.678\n",
      "Iteration: 42, Loss: -0.972, Noise Variance: 0.081, Signal Variance: 0.871, Lengthscale: 0.683\n",
      "Iteration: 43, Loss: -0.972, Noise Variance: 0.081, Signal Variance: 0.868, Lengthscale: 0.688\n",
      "Iteration: 44, Loss: -0.979, Noise Variance: 0.080, Signal Variance: 0.865, Lengthscale: 0.692\n",
      "Iteration: 45, Loss: -0.986, Noise Variance: 0.080, Signal Variance: 0.862, Lengthscale: 0.697\n",
      "Iteration: 46, Loss: -0.997, Noise Variance: 0.079, Signal Variance: 0.859, Lengthscale: 0.702\n",
      "Iteration: 47, Loss: -1.004, Noise Variance: 0.079, Signal Variance: 0.856, Lengthscale: 0.707\n",
      "Iteration: 48, Loss: -1.017, Noise Variance: 0.079, Signal Variance: 0.853, Lengthscale: 0.711\n",
      "Iteration: 49, Loss: -1.032, Noise Variance: 0.078, Signal Variance: 0.850, Lengthscale: 0.716\n",
      "Iteration: 50, Loss: -1.027, Noise Variance: 0.078, Signal Variance: 0.847, Lengthscale: 0.721\n",
      "Iteration: 51, Loss: -1.029, Noise Variance: 0.077, Signal Variance: 0.844, Lengthscale: 0.726\n",
      "Iteration: 52, Loss: -1.038, Noise Variance: 0.077, Signal Variance: 0.841, Lengthscale: 0.731\n",
      "Iteration: 53, Loss: -1.044, Noise Variance: 0.077, Signal Variance: 0.838, Lengthscale: 0.735\n",
      "Iteration: 54, Loss: -1.056, Noise Variance: 0.076, Signal Variance: 0.835, Lengthscale: 0.740\n",
      "Iteration: 55, Loss: -1.043, Noise Variance: 0.076, Signal Variance: 0.832, Lengthscale: 0.745\n",
      "Iteration: 56, Loss: -1.066, Noise Variance: 0.075, Signal Variance: 0.830, Lengthscale: 0.750\n",
      "Iteration: 57, Loss: -1.075, Noise Variance: 0.075, Signal Variance: 0.827, Lengthscale: 0.755\n",
      "Iteration: 58, Loss: -1.076, Noise Variance: 0.075, Signal Variance: 0.824, Lengthscale: 0.760\n",
      "Iteration: 59, Loss: -1.087, Noise Variance: 0.074, Signal Variance: 0.821, Lengthscale: 0.765\n",
      "Iteration: 60, Loss: -1.096, Noise Variance: 0.074, Signal Variance: 0.818, Lengthscale: 0.769\n",
      "Iteration: 61, Loss: -1.090, Noise Variance: 0.073, Signal Variance: 0.815, Lengthscale: 0.774\n",
      "Iteration: 62, Loss: -1.100, Noise Variance: 0.073, Signal Variance: 0.812, Lengthscale: 0.779\n",
      "Iteration: 63, Loss: -1.112, Noise Variance: 0.073, Signal Variance: 0.810, Lengthscale: 0.784\n",
      "Iteration: 64, Loss: -1.121, Noise Variance: 0.072, Signal Variance: 0.807, Lengthscale: 0.789\n",
      "Iteration: 65, Loss: -1.122, Noise Variance: 0.072, Signal Variance: 0.804, Lengthscale: 0.794\n",
      "Iteration: 66, Loss: -1.133, Noise Variance: 0.072, Signal Variance: 0.801, Lengthscale: 0.799\n",
      "Iteration: 67, Loss: -1.140, Noise Variance: 0.071, Signal Variance: 0.798, Lengthscale: 0.804\n",
      "Iteration: 68, Loss: -1.141, Noise Variance: 0.071, Signal Variance: 0.796, Lengthscale: 0.809\n",
      "Iteration: 69, Loss: -1.150, Noise Variance: 0.070, Signal Variance: 0.793, Lengthscale: 0.814\n",
      "Iteration: 70, Loss: -1.158, Noise Variance: 0.070, Signal Variance: 0.790, Lengthscale: 0.819\n",
      "Iteration: 71, Loss: -1.157, Noise Variance: 0.070, Signal Variance: 0.787, Lengthscale: 0.824\n",
      "Iteration: 72, Loss: -1.169, Noise Variance: 0.069, Signal Variance: 0.785, Lengthscale: 0.829\n",
      "Iteration: 73, Loss: -1.184, Noise Variance: 0.069, Signal Variance: 0.782, Lengthscale: 0.834\n",
      "Iteration: 74, Loss: -1.181, Noise Variance: 0.069, Signal Variance: 0.779, Lengthscale: 0.839\n",
      "Iteration: 75, Loss: -1.189, Noise Variance: 0.068, Signal Variance: 0.776, Lengthscale: 0.844\n",
      "Iteration: 76, Loss: -1.194, Noise Variance: 0.068, Signal Variance: 0.774, Lengthscale: 0.849\n",
      "Iteration: 77, Loss: -1.207, Noise Variance: 0.068, Signal Variance: 0.771, Lengthscale: 0.854\n",
      "Iteration: 78, Loss: -1.210, Noise Variance: 0.067, Signal Variance: 0.768, Lengthscale: 0.859\n",
      "Iteration: 79, Loss: -1.206, Noise Variance: 0.067, Signal Variance: 0.766, Lengthscale: 0.864\n",
      "Iteration: 80, Loss: -1.222, Noise Variance: 0.066, Signal Variance: 0.763, Lengthscale: 0.869\n",
      "Iteration: 81, Loss: -1.229, Noise Variance: 0.066, Signal Variance: 0.760, Lengthscale: 0.874\n",
      "Iteration: 82, Loss: -1.229, Noise Variance: 0.066, Signal Variance: 0.757, Lengthscale: 0.879\n",
      "Iteration: 83, Loss: -1.239, Noise Variance: 0.065, Signal Variance: 0.755, Lengthscale: 0.884\n",
      "Iteration: 84, Loss: -1.253, Noise Variance: 0.065, Signal Variance: 0.752, Lengthscale: 0.889\n",
      "Iteration: 85, Loss: -1.245, Noise Variance: 0.065, Signal Variance: 0.749, Lengthscale: 0.894\n",
      "Iteration: 86, Loss: -1.257, Noise Variance: 0.064, Signal Variance: 0.747, Lengthscale: 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 87, Loss: -1.261, Noise Variance: 0.064, Signal Variance: 0.744, Lengthscale: 0.905\n",
      "Iteration: 88, Loss: -1.268, Noise Variance: 0.064, Signal Variance: 0.742, Lengthscale: 0.910\n",
      "Iteration: 89, Loss: -1.284, Noise Variance: 0.063, Signal Variance: 0.739, Lengthscale: 0.915\n",
      "Iteration: 90, Loss: -1.284, Noise Variance: 0.063, Signal Variance: 0.736, Lengthscale: 0.920\n",
      "Iteration: 91, Loss: -1.298, Noise Variance: 0.063, Signal Variance: 0.734, Lengthscale: 0.925\n",
      "Iteration: 92, Loss: -1.301, Noise Variance: 0.062, Signal Variance: 0.731, Lengthscale: 0.930\n",
      "Iteration: 93, Loss: -1.301, Noise Variance: 0.062, Signal Variance: 0.728, Lengthscale: 0.936\n",
      "Iteration: 94, Loss: -1.304, Noise Variance: 0.062, Signal Variance: 0.726, Lengthscale: 0.941\n",
      "Iteration: 95, Loss: -1.309, Noise Variance: 0.061, Signal Variance: 0.723, Lengthscale: 0.946\n",
      "Iteration: 96, Loss: -1.325, Noise Variance: 0.061, Signal Variance: 0.721, Lengthscale: 0.951\n",
      "Iteration: 97, Loss: -1.326, Noise Variance: 0.061, Signal Variance: 0.718, Lengthscale: 0.956\n",
      "Iteration: 98, Loss: -1.329, Noise Variance: 0.060, Signal Variance: 0.716, Lengthscale: 0.961\n",
      "Iteration: 99, Loss: -1.342, Noise Variance: 0.060, Signal Variance: 0.713, Lengthscale: 0.967\n",
      "Time: 9.2 sec\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "model.vanilla_train(lr=1e-2, iter=100, verbose=True)\n",
    "t1 = time()\n",
    "print(\"Time: %.2g sec\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132bcc3e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04e576d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "likelihood.eval()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab36075",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "984df9f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  tensor(0.0106, device='cuda:0')\n",
      "NLL:  tensor(-0.8882, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.cg_tolerance(10000):\n",
    "    preds_test = likelihood(model(test_x))\n",
    "        \n",
    "    error = test_y - preds_test.mean\n",
    "    covar = preds_test.lazy_covariance_matrix.evaluate_kernel()\n",
    "    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=error.unsqueeze(-1), logdet=True)\n",
    "    \n",
    "    rmse = (error.square().sum()/test_y.shape[0]).sqrt()\n",
    "    nll = 0.5 * sum([inv_quad, logdet, error.size(-1)* np.log(2 * np.pi)])/test_y.shape[0]\n",
    "    \n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"NLL: \", nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee6ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
