{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e276dbe",
   "metadata": {},
   "source": [
    "# Benchmark Manifold GP Semi-Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36444a5",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d17d1f",
   "metadata": {},
   "source": [
    "This notebook provides an example of how to perform Gaussian Process Regression on a 1D manifold. In this example we consider a supervised learning scenario, namely the number of labeled data points is equivalent to the number of the sampled points from the underlying manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e9afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.spatial as ss\n",
    "from scipy.io import loadmat\n",
    "from time import time\n",
    "from manifold_gp.kernels.riemann_matern_kernel import RiemannMaternKernel\n",
    "from manifold_gp.models.riemann_gp import RiemannGP\n",
    "from gpytorch.priors import NormalPrior, GammaPrior\n",
    "from manifold_gp.utils.torch_helper import memory_allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75701656",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02483bf0",
   "metadata": {},
   "source": [
    "### Load & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af216c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bike, buzz_tomshardware, buzz_twitter, ctslices, elevators, protein, song, mnist, mnist_single\n",
    "dataset = 'ctslices'\n",
    "samples_split = 0.9\n",
    "preprocess = False\n",
    "normalize_features = False\n",
    "normalize_labels = True\n",
    "\n",
    "data = np.load('../datasets/'+dataset+'.npy')\n",
    "\n",
    "x = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "idx = np.random.permutation(x.shape[0])\n",
    "x = x[idx, :]\n",
    "y = y[idx]\n",
    "\n",
    "# x = data[:, :-1]\n",
    "# x = x - x.min(0)[0]\n",
    "# x = 2 * (x/ x.max(0)[0]) - 1\n",
    "# mu, std = x.mean(axis=0), x.std(axis=0)\n",
    "# x = (x - mu)/std\n",
    "\n",
    "num_samples = int(samples_split * len(data))\n",
    "sampled_x, sampled_y = x[:num_samples, :], data[:num_samples, -1]\n",
    "test_x, test_y = x[num_samples:, :], data[num_samples:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454bcc7f-115a-486f-b055-0495b7565d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48150, 385)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd8811d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preprocess:\n",
    "    # # remove coincident points\n",
    "    # sampled_x, id_unique = np.unique(sampled_x, axis=0, return_index=True)\n",
    "    # sampled_y = sampled_y[id_unique]\n",
    "\n",
    "    # cut between x% and y% percentile of distances\n",
    "    num_avg = 1\n",
    "    p_start, p_end = 0.1, 0.9\n",
    "    num_samples = sampled_x.shape[0]\n",
    "    \n",
    "    import faiss\n",
    "    res = faiss.StandardGpuResources()\n",
    "    knn = faiss.GpuIndexIVFFlat(res, sampled_x.shape[1], 1, faiss.METRIC_L2)\n",
    "    knn.train(sampled_x)\n",
    "    knn.add(sampled_x)\n",
    "    v = np.sqrt(knn.search(sampled_x, num_avg+1)[0][:,1:])\n",
    "    idx = np.argsort(v.mean(axis=1))\n",
    "    idx = np.delete(idx, np.arange(int(num_samples*p_start),int(num_samples*p_end)))\n",
    "    sampled_x = np.delete(sampled_x, idx, axis=0)\n",
    "    sampled_y = np.delete(sampled_y, idx)\n",
    "m = sampled_x.shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b397ed8-5a15-41f7-b3a0-ab146fe7d556",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "res = faiss.StandardGpuResources()\n",
    "knn = faiss.GpuIndexIVFFlat(res, sampled_x.shape[1], 1, faiss.METRIC_L2)\n",
    "knn.train(sampled_x)\n",
    "knn.add(sampled_x)\n",
    "v, i = knn.search(sampled_x, 2)\n",
    "v = np.sqrt(v[:,1:]).mean(axis=1)\n",
    "\n",
    "plt.hist(np.sort(v), density=False, bins=100)  # density=False would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331daec5",
   "metadata": {},
   "source": [
    "### Trainset & Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163309fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(0.05 * m)\n",
    "train_idx = torch.arange(0, train_split)\n",
    "train_x, train_y = sampled_x[:train_split], sampled_y[:train_split]\n",
    "\n",
    "sampled_x = torch.from_numpy(sampled_x).float()\n",
    "train_x, train_y = torch.from_numpy(train_x).float(), torch.from_numpy(train_y).float()\n",
    "test_x, test_y = torch.from_numpy(test_x).float(), torch.from_numpy(test_y).float()\n",
    "\n",
    "if normalize_features:\n",
    "    mu_x, std_x = sampled_x.mean(dim=-2, keepdim=True), sampled_x.std(dim=-2, keepdim=True) + 1e-6\n",
    "    sampled_x.sub_(mu_x).div_(std_x)\n",
    "    train_x.sub_(mu_x).div_(std_x)\n",
    "    test_x.sub_(mu_x).div_(std_x)\n",
    "    \n",
    "if normalize_labels:\n",
    "    mu_y, std_y = train_y.mean(), train_y.std()\n",
    "    train_y.sub_(mu_y).div_(std_y)\n",
    "    test_y.sub_(mu_y).div_(std_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87581de",
   "metadata": {},
   "source": [
    "### Move Data to Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c91b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_x = sampled_x.contiguous()\n",
    "train_idx = train_idx.contiguous()\n",
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "sampled_x = sampled_x.to(device)\n",
    "train_idx = train_idx.to(device)\n",
    "train_x, train_y = train_x.to(device), train_y.to(device)\n",
    "test_x, test_y = test_x.to(device), test_y.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d4275",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83460075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(\n",
    "    noise_constraint=gpytorch.constraints.GreaterThan(1e-8),\n",
    "    noise_prior=None  # NormalPrior(torch.tensor([0.0]).to(device),  torch.tensor([1/9]).sqrt().to(device))\n",
    ")\n",
    "\n",
    "kernel = gpytorch.kernels.ScaleKernel(\n",
    "    RiemannMaternKernel(\n",
    "        nu=4,\n",
    "        nodes=sampled_x,\n",
    "        neighbors=100,\n",
    "        operator=\"randomwalk\",\n",
    "        method=\"exact\",\n",
    "        modes=500,\n",
    "        ball_scale=100.0,\n",
    "        prior_bandwidth=True,\n",
    "    ),\n",
    "    outputscale_prior=None # NormalPrior(torch.tensor([1.0]).to(device),  torch.tensor([1/9]).sqrt().to(device))\n",
    ")\n",
    "\n",
    "model = RiemannGP(train_x, train_y, likelihood, kernel, train_idx).to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a098f3d4-9703-4dbb-9274-9027de792129",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "v, i = kernel.base_kernel.knn.search(sampled_x, 2)\n",
    "v = v[:,1:].mean(axis=1).sqrt()\n",
    "\n",
    "plt.hist(np.sort(v.cpu()), density=False, bins=100)  # density=False would make counts\n",
    "plt.vlines(kernel.base_kernel.eps_gte.item(), 0, 1000, colors='k', linestyles='dashed')\n",
    "# plt.plot(np.sort(v.cpu()), 1e3*kernel.base_kernel.epsilon_prior.log_prob(np.sort(v.cpu())).exp().cpu())\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data')\n",
    "kernel.base_kernel.eps_gte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14763b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a6cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "hypers = {\n",
    "    'likelihood.noise_covar.noise': 1e-2,\n",
    "    'covar_module.base_kernel.epsilon': 1.5,\n",
    "    'covar_module.base_kernel.lengthscale': 10.0,\n",
    "    'covar_module.outputscale': 1.0,\n",
    "}\n",
    "model.initialize(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38527263-1871-41e1-9f66-c302b7041966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 4285.349, NoiseVar: 0.010, SignalVar: 0.00085, Lengthscale: 10.000, Epsilon: 1.500\n",
      "Iter: 1, Loss: 4198.303, NoiseVar: 0.010, SignalVar: 0.00086, Lengthscale: 10.010, Epsilon: 1.508\n",
      "Iter: 2, Loss: 4135.141, NoiseVar: 0.010, SignalVar: 0.00086, Lengthscale: 10.020, Epsilon: 1.516\n",
      "Iter: 3, Loss: 4073.111, NoiseVar: 0.010, SignalVar: 0.00087, Lengthscale: 10.030, Epsilon: 1.523\n",
      "Iter: 4, Loss: 3992.686, NoiseVar: 0.010, SignalVar: 0.00088, Lengthscale: 10.040, Epsilon: 1.531\n",
      "Iter: 5, Loss: 3972.336, NoiseVar: 0.011, SignalVar: 0.00089, Lengthscale: 10.049, Epsilon: 1.539\n",
      "Iter: 6, Loss: 3936.304, NoiseVar: 0.011, SignalVar: 0.00090, Lengthscale: 10.059, Epsilon: 1.546\n",
      "Iter: 7, Loss: 3899.121, NoiseVar: 0.011, SignalVar: 0.00091, Lengthscale: 10.068, Epsilon: 1.554\n",
      "Iter: 8, Loss: 3838.942, NoiseVar: 0.011, SignalVar: 0.00092, Lengthscale: 10.077, Epsilon: 1.561\n",
      "Iter: 9, Loss: 3809.182, NoiseVar: 0.011, SignalVar: 0.00092, Lengthscale: 10.085, Epsilon: 1.568\n",
      "Iter: 10, Loss: 3796.188, NoiseVar: 0.011, SignalVar: 0.00093, Lengthscale: 10.093, Epsilon: 1.575\n",
      "Iter: 11, Loss: 3775.469, NoiseVar: 0.011, SignalVar: 0.00094, Lengthscale: 10.101, Epsilon: 1.582\n",
      "Iter: 12, Loss: 3762.162, NoiseVar: 0.011, SignalVar: 0.00095, Lengthscale: 10.108, Epsilon: 1.589\n",
      "Iter: 13, Loss: 3746.714, NoiseVar: 0.011, SignalVar: 0.00096, Lengthscale: 10.115, Epsilon: 1.595\n",
      "Iter: 14, Loss: 3745.158, NoiseVar: 0.011, SignalVar: 0.00096, Lengthscale: 10.121, Epsilon: 1.602\n",
      "Iter: 15, Loss: 3724.360, NoiseVar: 0.011, SignalVar: 0.00097, Lengthscale: 10.126, Epsilon: 1.608\n",
      "Iter: 16, Loss: 3711.764, NoiseVar: 0.011, SignalVar: 0.00098, Lengthscale: 10.130, Epsilon: 1.613\n",
      "Iter: 17, Loss: 3696.382, NoiseVar: 0.012, SignalVar: 0.00099, Lengthscale: 10.134, Epsilon: 1.619\n",
      "Iter: 18, Loss: 3697.774, NoiseVar: 0.012, SignalVar: 0.00099, Lengthscale: 10.136, Epsilon: 1.624\n",
      "Iter: 19, Loss: 3697.744, NoiseVar: 0.012, SignalVar: 0.00100, Lengthscale: 10.138, Epsilon: 1.629\n",
      "Iter: 20, Loss: 3703.730, NoiseVar: 0.012, SignalVar: 0.00100, Lengthscale: 10.139, Epsilon: 1.633\n",
      "Iter: 21, Loss: 3696.569, NoiseVar: 0.012, SignalVar: 0.00101, Lengthscale: 10.140, Epsilon: 1.638\n",
      "Iter: 22, Loss: 3693.935, NoiseVar: 0.012, SignalVar: 0.00101, Lengthscale: 10.139, Epsilon: 1.642\n",
      "Iter: 23, Loss: 3696.289, NoiseVar: 0.012, SignalVar: 0.00102, Lengthscale: 10.138, Epsilon: 1.645\n",
      "Iter: 24, Loss: 3703.888, NoiseVar: 0.012, SignalVar: 0.00102, Lengthscale: 10.136, Epsilon: 1.649\n",
      "Iter: 25, Loss: 3692.678, NoiseVar: 0.012, SignalVar: 0.00103, Lengthscale: 10.133, Epsilon: 1.652\n",
      "Iter: 26, Loss: 3678.482, NoiseVar: 0.012, SignalVar: 0.00103, Lengthscale: 10.130, Epsilon: 1.655\n",
      "Iter: 27, Loss: 3692.147, NoiseVar: 0.012, SignalVar: 0.00104, Lengthscale: 10.125, Epsilon: 1.657\n",
      "Iter: 28, Loss: 3688.672, NoiseVar: 0.012, SignalVar: 0.00104, Lengthscale: 10.121, Epsilon: 1.659\n",
      "Iter: 29, Loss: 3685.717, NoiseVar: 0.012, SignalVar: 0.00104, Lengthscale: 10.115, Epsilon: 1.661\n",
      "Iter: 30, Loss: 3690.985, NoiseVar: 0.012, SignalVar: 0.00104, Lengthscale: 10.110, Epsilon: 1.663\n",
      "Iter: 31, Loss: 3703.502, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.103, Epsilon: 1.665\n",
      "Iter: 32, Loss: 3710.668, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.097, Epsilon: 1.666\n",
      "Iter: 33, Loss: 3699.600, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.090, Epsilon: 1.667\n",
      "Iter: 34, Loss: 3691.326, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.082, Epsilon: 1.668\n",
      "Iter: 35, Loss: 3693.775, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.075, Epsilon: 1.668\n",
      "Iter: 36, Loss: 3698.076, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.067, Epsilon: 1.669\n",
      "Iter: 37, Loss: 3677.587, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.058, Epsilon: 1.669\n",
      "Iter: 38, Loss: 3695.424, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.050, Epsilon: 1.669\n",
      "Iter: 39, Loss: 3705.125, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.041, Epsilon: 1.669\n",
      "Iter: 40, Loss: 3685.254, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.032, Epsilon: 1.669\n",
      "Iter: 41, Loss: 3690.108, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.023, Epsilon: 1.668\n",
      "Iter: 42, Loss: 3684.667, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.013, Epsilon: 1.668\n",
      "Iter: 43, Loss: 3701.202, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 10.004, Epsilon: 1.667\n",
      "Iter: 44, Loss: 3686.933, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 9.994, Epsilon: 1.667\n",
      "Iter: 45, Loss: 3694.797, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 9.985, Epsilon: 1.666\n",
      "Iter: 46, Loss: 3680.164, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 9.975, Epsilon: 1.665\n",
      "Iter: 47, Loss: 3688.730, NoiseVar: 0.012, SignalVar: 0.00105, Lengthscale: 9.965, Epsilon: 1.665\n",
      "Iter: 48, Loss: 3694.908, NoiseVar: 0.013, SignalVar: 0.00105, Lengthscale: 9.956, Epsilon: 1.664\n",
      "Iter: 49, Loss: 3684.510, NoiseVar: 0.013, SignalVar: 0.00105, Lengthscale: 9.946, Epsilon: 1.663\n",
      "Iter: 50, Loss: 3675.074, NoiseVar: 0.013, SignalVar: 0.00105, Lengthscale: 9.936, Epsilon: 1.662\n",
      "Iter: 51, Loss: 3682.492, NoiseVar: 0.013, SignalVar: 0.00105, Lengthscale: 9.926, Epsilon: 1.661\n",
      "Iter: 52, Loss: 3669.482, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.917, Epsilon: 1.661\n",
      "Iter: 53, Loss: 3677.525, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.907, Epsilon: 1.660\n",
      "Iter: 54, Loss: 3687.250, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.898, Epsilon: 1.659\n",
      "Iter: 55, Loss: 3700.668, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.888, Epsilon: 1.658\n",
      "Iter: 56, Loss: 3666.234, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.878, Epsilon: 1.658\n",
      "Iter: 57, Loss: 3669.782, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.869, Epsilon: 1.657\n",
      "Iter: 58, Loss: 3675.208, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.859, Epsilon: 1.656\n",
      "Iter: 59, Loss: 3666.656, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.849, Epsilon: 1.656\n",
      "Iter: 60, Loss: 3690.694, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.840, Epsilon: 1.655\n",
      "Iter: 61, Loss: 3668.856, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.831, Epsilon: 1.655\n",
      "Iter: 62, Loss: 3672.272, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.821, Epsilon: 1.654\n",
      "Iter: 63, Loss: 3672.342, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.812, Epsilon: 1.654\n",
      "Iter: 64, Loss: 3661.808, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.803, Epsilon: 1.654\n",
      "Iter: 65, Loss: 3675.674, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.794, Epsilon: 1.653\n",
      "Iter: 66, Loss: 3659.111, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.785, Epsilon: 1.653\n",
      "Iter: 67, Loss: 3672.178, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.776, Epsilon: 1.653\n",
      "Iter: 68, Loss: 3672.347, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.767, Epsilon: 1.653\n",
      "Iter: 69, Loss: 3668.794, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.759, Epsilon: 1.653\n",
      "Iter: 70, Loss: 3664.136, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.750, Epsilon: 1.653\n",
      "Iter: 71, Loss: 3647.790, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.741, Epsilon: 1.653\n",
      "Iter: 72, Loss: 3671.956, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.732, Epsilon: 1.653\n",
      "Iter: 73, Loss: 3660.055, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.724, Epsilon: 1.654\n",
      "Iter: 74, Loss: 3679.691, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.715, Epsilon: 1.654\n",
      "Iter: 75, Loss: 3671.610, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.707, Epsilon: 1.654\n",
      "Iter: 76, Loss: 3676.943, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.698, Epsilon: 1.654\n",
      "Iter: 77, Loss: 3658.126, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.690, Epsilon: 1.655\n",
      "Iter: 78, Loss: 3670.197, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.682, Epsilon: 1.655\n",
      "Iter: 79, Loss: 3669.083, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.673, Epsilon: 1.656\n",
      "Iter: 80, Loss: 3673.561, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.665, Epsilon: 1.656\n",
      "Iter: 81, Loss: 3669.189, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.656, Epsilon: 1.657\n",
      "Iter: 82, Loss: 3673.014, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.648, Epsilon: 1.657\n",
      "Iter: 83, Loss: 3654.594, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.639, Epsilon: 1.658\n",
      "Iter: 84, Loss: 3665.096, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.631, Epsilon: 1.658\n",
      "Iter: 85, Loss: 3657.494, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.622, Epsilon: 1.659\n",
      "Iter: 86, Loss: 3648.499, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.614, Epsilon: 1.659\n",
      "Iter: 87, Loss: 3661.257, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.606, Epsilon: 1.660\n",
      "Iter: 88, Loss: 3659.090, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.597, Epsilon: 1.660\n",
      "Iter: 89, Loss: 3649.390, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.589, Epsilon: 1.661\n",
      "Iter: 90, Loss: 3662.969, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.580, Epsilon: 1.661\n",
      "Iter: 91, Loss: 3670.993, NoiseVar: 0.013, SignalVar: 0.00104, Lengthscale: 9.572, Epsilon: 1.661\n",
      "Iter: 92, Loss: 3662.032, NoiseVar: 0.013, SignalVar: 0.00105, Lengthscale: 9.563, Epsilon: 1.662\n",
      "Iter: 93, Loss: 3654.334, NoiseVar: 0.013, SignalVar: 0.00105, Lengthscale: 9.554, Epsilon: 1.662\n",
      "Iter: 94, Loss: 3661.915, NoiseVar: 0.013, SignalVar: 0.00105, Lengthscale: 9.546, Epsilon: 1.663\n",
      "Iter: 95, Loss: 3660.005, NoiseVar: 0.014, SignalVar: 0.00105, Lengthscale: 9.537, Epsilon: 1.663\n",
      "Iter: 96, Loss: 3659.361, NoiseVar: 0.014, SignalVar: 0.00105, Lengthscale: 9.528, Epsilon: 1.663\n",
      "Iter: 97, Loss: 3641.906, NoiseVar: 0.014, SignalVar: 0.00105, Lengthscale: 9.520, Epsilon: 1.664\n",
      "Iter: 98, Loss: 3649.218, NoiseVar: 0.014, SignalVar: 0.00105, Lengthscale: 9.511, Epsilon: 1.664\n",
      "Iter: 99, Loss: 3663.970, NoiseVar: 0.014, SignalVar: 0.00105, Lengthscale: 9.502, Epsilon: 1.665\n",
      "Time: 6.1e+02 sec\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "model.manifold_informed_train(lr=1e-2, iter=100,\n",
    "                              decay_step_size=100, decay_magnitude=1.0, \n",
    "                              norm_step_size=10, norm_rand_vec=100, \n",
    "                              verbose=True, save=False)\n",
    "t1 = time()\n",
    "print(\"Time: %.2g sec\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cf91fda-1cce-4fbd-a8a7-120b3b060569",
   "metadata": {},
   "source": [
    "kernel.outputscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0a4e9d9-38e7-40eb-b44c-2949e27f2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/model_state.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90a4156-bb3c-4f59-8dcd-05cc67235326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/model_state.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c816c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11429e67-4866-462e-a718-f602f4b004bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.base_kernel.method = \"lanczos\"\n",
    "kernel.base_kernel.modes = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6f0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "likelihood.eval()\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "796a07f1-62b7-4766-b927-7811c7e12770",
   "metadata": {},
   "source": [
    "kernel(sampled_x,sampled_x).evaluate().diag().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d201b909",
   "metadata": {},
   "source": [
    "\n",
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "998d4b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  tensor(3.8087, device='cuda:0')\n",
      "NLL:  tensor(113.0177, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    preds_test = likelihood(model(test_x))\n",
    "\n",
    "    mean_test = preds_test.mean\n",
    "        \n",
    "    error = test_y - preds_test.mean\n",
    "    covar = preds_test.lazy_covariance_matrix.evaluate_kernel()\n",
    "    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=error.unsqueeze(-1), logdet=True)\n",
    "    \n",
    "    rmse = (error.square().sum()/test_y.shape[0]).sqrt()\n",
    "    nll = 0.5 * sum([inv_quad, logdet, error.size(-1)* np.log(2 * np.pi)])/test_y.shape[0]\n",
    "    model._clear_cache()\n",
    "    \n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"NLL: \", nll)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbf89f8a-bd9b-43bc-a3a3-ecd2f23f1de2",
   "metadata": {},
   "source": [
    "with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.cg_tolerance(10000):\n",
    "    preds_train = likelihood(model(train_x))\n",
    "        \n",
    "    error = train_y - preds_train.mean\n",
    "    covar = preds_train.lazy_covariance_matrix.evaluate_kernel()\n",
    "    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=error.unsqueeze(-1), logdet=True)\n",
    "    \n",
    "    rmse = (error.square().sum()/train_y.shape[0]).sqrt()\n",
    "    nll = 0.5 * sum([inv_quad, logdet, error.size(-1)* np.log(2 * np.pi)])/train_y.shape[0]\n",
    "    model._clear_cache()\n",
    "    \n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"NLL: \", nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c6cbd-8f96-431e-b6ab-d99d34b15988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
