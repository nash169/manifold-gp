{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e276dbe",
   "metadata": {},
   "source": [
    "# Benchmark Manifold GP Semi-Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36444a5",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d17d1f",
   "metadata": {},
   "source": [
    "This notebook provides an example of how to perform Gaussian Process Regression on a 1D manifold. In this example we consider a supervised learning scenario, namely the number of labeled data points is equivalent to the number of the sampled points from the underlying manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e9afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.spatial as ss\n",
    "from time import time\n",
    "from manifold_gp.kernels.riemann_matern_kernel import RiemannMaternKernel\n",
    "from manifold_gp.models.riemann_gp import RiemannGP\n",
    "from gpytorch.priors import NormalPrior, GammaPrior\n",
    "\n",
    "from manifold_gp.utils.torch_helper import memory_allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75701656",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02483bf0",
   "metadata": {},
   "source": [
    "### Load & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af216c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "dataset = 'mnist'\n",
    "\n",
    "data = np.loadtxt('datasets/'+dataset+'_train.csv')\n",
    "sampled_x, sampled_y = data[:, 2:], data[:, 1]\n",
    "rand_idx = torch.randperm(sampled_x.shape[0])\n",
    "sampled_x, sampled_y = sampled_x[rand_idx], sampled_y[rand_idx]\n",
    "del rand_idx\n",
    "\n",
    "data = np.loadtxt('datasets/'+dataset+'_test.csv')\n",
    "test_x, test_y = data[:, 2:], data[:, 1]\n",
    "    \n",
    "preprocess = False\n",
    "normalize_features = False\n",
    "normalize_labels = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd8811d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preprocess:\n",
    "    # remove coincident points\n",
    "    sampled_x, id_unique = np.unique(sampled_x, axis=0, return_index=True)\n",
    "    sampled_y = sampled_y[id_unique]\n",
    "\n",
    "    # cut between 0.1 and 0.9 percentile of distances\n",
    "    import faiss\n",
    "    res = faiss.StandardGpuResources()\n",
    "    knn = faiss.GpuIndexIVFFlat(res, sampled_x.shape[1], 1, faiss.METRIC_L2)\n",
    "    knn.train(sampled_x)\n",
    "    knn.add(sampled_x)\n",
    "    v = np.sqrt(knn.search(sampled_x, 51)[0][:,1:])\n",
    "    idx = np.argsort(v.mean(axis=1).ravel())\n",
    "    percentile_start = int(np.round(idx.shape[0]*0.10))\n",
    "    percentile_end = int(np.round(idx.shape[0]*0.90))\n",
    "    sampled_x = sampled_x[idx[percentile_start:percentile_end], :]\n",
    "    sampled_y = sampled_y[idx[percentile_start:percentile_end]]\n",
    "    del knn\n",
    "m = sampled_x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331daec5",
   "metadata": {},
   "source": [
    "### Trainset & Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163309fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.1 * m)\n",
    "train_idx = torch.arange(0, split)\n",
    "train_x, train_y = sampled_x[:split], sampled_y[:split]\n",
    "\n",
    "sampled_x = torch.from_numpy(sampled_x).float()\n",
    "train_x, train_y = torch.from_numpy(train_x).float(), torch.from_numpy(train_y).float()\n",
    "test_x, test_y = torch.from_numpy(test_x).float(), torch.from_numpy(test_y).float()\n",
    "\n",
    "if normalize_features:\n",
    "    mu_x, std_x = sampled_x.mean(dim=-2, keepdim=True), sampled_x.std(dim=-2, keepdim=True) + 1e-6\n",
    "    sampled_x.sub_(mu_x).div_(std_x)\n",
    "    train_x.sub_(mu_x).div_(std_x)\n",
    "    test_x.sub_(mu_x).div_(std_x)\n",
    "    \n",
    "if normalize_labels:\n",
    "    mu_y, std_y = train_y.mean(), train_y.std()\n",
    "    train_y.sub_(mu_y).div_(std_y)\n",
    "    test_y.sub_(mu_y).div_(std_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87581de",
   "metadata": {},
   "source": [
    "### Move Data to Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c91b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_x = sampled_x.contiguous()\n",
    "train_idx = train_idx.contiguous()\n",
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "sampled_x = sampled_x.to(device)\n",
    "train_idx = train_idx.to(device)\n",
    "train_x, train_y = train_x.to(device), train_y.to(device)\n",
    "test_x, test_y = test_x.to(device), test_y.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d4275",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83460075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(\n",
    "    noise_constraint=gpytorch.constraints.GreaterThan(1e-8),\n",
    "    noise_prior=None  # NormalPrior(torch.tensor([0.0]).to(device),  torch.tensor([1/9]).sqrt().to(device))\n",
    ")\n",
    "\n",
    "kernel = gpytorch.kernels.ScaleKernel(\n",
    "    RiemannMaternKernel(\n",
    "        nu=2,\n",
    "        nodes=sampled_x,\n",
    "        neighbors=50,\n",
    "        operator=\"randomwalk\",\n",
    "        modes=100,\n",
    "        ball_scale=10.0,\n",
    "        prior_bandwidth=False,\n",
    "    ),\n",
    "    outputscale_prior=None # NormalPrior(torch.tensor([1.0]).to(device),  torch.tensor([1/9]).sqrt().to(device))\n",
    ")\n",
    "\n",
    "model = RiemannGP(train_x, train_y, likelihood, kernel, train_idx).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14763b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a6cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "hypers = {\n",
    "    'likelihood.noise_covar.noise': 1e-2,\n",
    "    'covar_module.base_kernel.epsilon': 0.5,\n",
    "    'covar_module.base_kernel.lengthscale': 1.0,\n",
    "    'covar_module.outputscale': 1.0,\n",
    "}\n",
    "model.initialize(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5377308c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, LR: 0.010, Loss: 405.043, NoiseVar: 0.010, SignalVar: 2.073, Lengthscale: 1.000, Epsilon: 0.500\n",
      "Iter: 1, LR: 0.010, Loss: 400.178, NoiseVar: 0.010, SignalVar: 2.064, Lengthscale: 1.006, Epsilon: 0.496\n",
      "Iter: 2, LR: 0.010, Loss: 399.025, NoiseVar: 0.010, SignalVar: 2.055, Lengthscale: 1.013, Epsilon: 0.492\n",
      "Iter: 3, LR: 0.010, Loss: 392.599, NoiseVar: 0.010, SignalVar: 2.046, Lengthscale: 1.019, Epsilon: 0.488\n",
      "Iter: 4, LR: 0.010, Loss: 386.529, NoiseVar: 0.010, SignalVar: 2.038, Lengthscale: 1.025, Epsilon: 0.484\n",
      "Iter: 5, LR: 0.010, Loss: 382.694, NoiseVar: 0.010, SignalVar: 2.029, Lengthscale: 1.032, Epsilon: 0.481\n",
      "Iter: 6, LR: 0.010, Loss: 378.320, NoiseVar: 0.009, SignalVar: 2.020, Lengthscale: 1.038, Epsilon: 0.477\n",
      "Iter: 7, LR: 0.010, Loss: 372.158, NoiseVar: 0.009, SignalVar: 2.012, Lengthscale: 1.045, Epsilon: 0.473\n",
      "Iter: 8, LR: 0.010, Loss: 366.392, NoiseVar: 0.009, SignalVar: 2.003, Lengthscale: 1.051, Epsilon: 0.469\n",
      "Iter: 9, LR: 0.010, Loss: 360.961, NoiseVar: 0.009, SignalVar: 1.994, Lengthscale: 1.058, Epsilon: 0.465\n",
      "Iter: 10, LR: 0.010, Loss: 357.038, NoiseVar: 0.009, SignalVar: 1.986, Lengthscale: 1.065, Epsilon: 0.462\n",
      "Iter: 11, LR: 0.010, Loss: 350.229, NoiseVar: 0.009, SignalVar: 1.978, Lengthscale: 1.072, Epsilon: 0.458\n",
      "Iter: 12, LR: 0.010, Loss: 346.911, NoiseVar: 0.009, SignalVar: 1.969, Lengthscale: 1.079, Epsilon: 0.454\n",
      "Iter: 13, LR: 0.010, Loss: 338.491, NoiseVar: 0.009, SignalVar: 1.961, Lengthscale: 1.086, Epsilon: 0.450\n",
      "Iter: 14, LR: 0.010, Loss: 332.392, NoiseVar: 0.009, SignalVar: 1.953, Lengthscale: 1.093, Epsilon: 0.447\n",
      "Iter: 15, LR: 0.010, Loss: 323.832, NoiseVar: 0.009, SignalVar: 1.945, Lengthscale: 1.100, Epsilon: 0.443\n",
      "Iter: 16, LR: 0.010, Loss: 320.473, NoiseVar: 0.009, SignalVar: 1.937, Lengthscale: 1.108, Epsilon: 0.439\n",
      "Iter: 17, LR: 0.010, Loss: 311.477, NoiseVar: 0.008, SignalVar: 1.930, Lengthscale: 1.115, Epsilon: 0.436\n",
      "Iter: 18, LR: 0.010, Loss: 305.076, NoiseVar: 0.008, SignalVar: 1.922, Lengthscale: 1.123, Epsilon: 0.432\n",
      "Iter: 19, LR: 0.010, Loss: 298.772, NoiseVar: 0.008, SignalVar: 1.915, Lengthscale: 1.130, Epsilon: 0.429\n",
      "Iter: 20, LR: 0.010, Loss: 290.764, NoiseVar: 0.008, SignalVar: 1.908, Lengthscale: 1.138, Epsilon: 0.425\n",
      "Iter: 21, LR: 0.010, Loss: 280.827, NoiseVar: 0.008, SignalVar: 1.900, Lengthscale: 1.146, Epsilon: 0.421\n",
      "Iter: 22, LR: 0.010, Loss: 275.293, NoiseVar: 0.008, SignalVar: 1.893, Lengthscale: 1.154, Epsilon: 0.418\n",
      "Iter: 23, LR: 0.010, Loss: 266.092, NoiseVar: 0.008, SignalVar: 1.887, Lengthscale: 1.162, Epsilon: 0.414\n",
      "Iter: 24, LR: 0.010, Loss: 255.720, NoiseVar: 0.008, SignalVar: 1.880, Lengthscale: 1.170, Epsilon: 0.411\n",
      "Iter: 25, LR: 0.010, Loss: 247.101, NoiseVar: 0.008, SignalVar: 1.874, Lengthscale: 1.178, Epsilon: 0.407\n",
      "Iter: 26, LR: 0.010, Loss: 239.649, NoiseVar: 0.008, SignalVar: 1.867, Lengthscale: 1.187, Epsilon: 0.404\n",
      "Iter: 27, LR: 0.010, Loss: 230.417, NoiseVar: 0.008, SignalVar: 1.861, Lengthscale: 1.195, Epsilon: 0.400\n",
      "Iter: 28, LR: 0.010, Loss: 219.523, NoiseVar: 0.007, SignalVar: 1.855, Lengthscale: 1.204, Epsilon: 0.396\n",
      "Iter: 29, LR: 0.010, Loss: 207.979, NoiseVar: 0.007, SignalVar: 1.849, Lengthscale: 1.213, Epsilon: 0.393\n",
      "Iter: 30, LR: 0.010, Loss: 197.246, NoiseVar: 0.007, SignalVar: 1.843, Lengthscale: 1.221, Epsilon: 0.389\n",
      "Iter: 31, LR: 0.010, Loss: 189.210, NoiseVar: 0.007, SignalVar: 1.838, Lengthscale: 1.230, Epsilon: 0.386\n",
      "Iter: 32, LR: 0.010, Loss: 177.806, NoiseVar: 0.007, SignalVar: 1.832, Lengthscale: 1.239, Epsilon: 0.382\n",
      "Iter: 33, LR: 0.010, Loss: 166.064, NoiseVar: 0.007, SignalVar: 1.827, Lengthscale: 1.248, Epsilon: 0.379\n",
      "Iter: 34, LR: 0.010, Loss: 154.487, NoiseVar: 0.007, SignalVar: 1.822, Lengthscale: 1.257, Epsilon: 0.375\n",
      "Iter: 35, LR: 0.010, Loss: 140.823, NoiseVar: 0.007, SignalVar: 1.817, Lengthscale: 1.267, Epsilon: 0.372\n",
      "Iter: 36, LR: 0.010, Loss: 127.073, NoiseVar: 0.007, SignalVar: 1.813, Lengthscale: 1.276, Epsilon: 0.368\n",
      "Iter: 37, LR: 0.010, Loss: 120.095, NoiseVar: 0.007, SignalVar: 1.808, Lengthscale: 1.285, Epsilon: 0.365\n",
      "Iter: 38, LR: 0.010, Loss: 103.107, NoiseVar: 0.007, SignalVar: 1.804, Lengthscale: 1.295, Epsilon: 0.361\n",
      "Iter: 39, LR: 0.010, Loss: 91.632, NoiseVar: 0.007, SignalVar: 1.799, Lengthscale: 1.304, Epsilon: 0.357\n",
      "Iter: 40, LR: 0.010, Loss: 74.999, NoiseVar: 0.006, SignalVar: 1.795, Lengthscale: 1.314, Epsilon: 0.354\n",
      "Iter: 41, LR: 0.010, Loss: 62.047, NoiseVar: 0.006, SignalVar: 1.791, Lengthscale: 1.324, Epsilon: 0.350\n",
      "Iter: 42, LR: 0.010, Loss: 48.175, NoiseVar: 0.006, SignalVar: 1.788, Lengthscale: 1.334, Epsilon: 0.347\n",
      "Iter: 43, LR: 0.010, Loss: 31.322, NoiseVar: 0.006, SignalVar: 1.784, Lengthscale: 1.344, Epsilon: 0.343\n",
      "Iter: 44, LR: 0.010, Loss: 17.669, NoiseVar: 0.006, SignalVar: 1.780, Lengthscale: 1.353, Epsilon: 0.340\n",
      "Iter: 45, LR: 0.010, Loss: 2.371, NoiseVar: 0.006, SignalVar: 1.776, Lengthscale: 1.363, Epsilon: 0.336\n",
      "Iter: 46, LR: 0.010, Loss: -8.027, NoiseVar: 0.006, SignalVar: 1.773, Lengthscale: 1.374, Epsilon: 0.333\n",
      "Iter: 47, LR: 0.010, Loss: -27.021, NoiseVar: 0.006, SignalVar: 1.769, Lengthscale: 1.384, Epsilon: 0.330\n",
      "Iter: 48, LR: 0.010, Loss: -43.286, NoiseVar: 0.006, SignalVar: 1.765, Lengthscale: 1.394, Epsilon: 0.326\n",
      "Iter: 49, LR: 0.010, Loss: -59.513, NoiseVar: 0.006, SignalVar: 1.762, Lengthscale: 1.404, Epsilon: 0.323\n",
      "Iter: 50, LR: 0.010, Loss: -85.996, NoiseVar: 0.006, SignalVar: 1.758, Lengthscale: 1.414, Epsilon: 0.319\n",
      "Iter: 51, LR: 0.010, Loss: -92.800, NoiseVar: 0.006, SignalVar: 1.754, Lengthscale: 1.425, Epsilon: 0.316\n",
      "Iter: 52, LR: 0.010, Loss: -114.125, NoiseVar: 0.006, SignalVar: 1.750, Lengthscale: 1.435, Epsilon: 0.312\n",
      "Iter: 53, LR: 0.010, Loss: -136.052, NoiseVar: 0.005, SignalVar: 1.746, Lengthscale: 1.445, Epsilon: 0.309\n",
      "Iter: 54, LR: 0.010, Loss: -151.024, NoiseVar: 0.005, SignalVar: 1.741, Lengthscale: 1.456, Epsilon: 0.305\n",
      "Iter: 55, LR: 0.010, Loss: -166.987, NoiseVar: 0.005, SignalVar: 1.737, Lengthscale: 1.466, Epsilon: 0.302\n",
      "Iter: 56, LR: 0.010, Loss: -189.698, NoiseVar: 0.005, SignalVar: 1.732, Lengthscale: 1.477, Epsilon: 0.299\n",
      "Iter: 57, LR: 0.010, Loss: -207.741, NoiseVar: 0.005, SignalVar: 1.728, Lengthscale: 1.487, Epsilon: 0.295\n",
      "Iter: 58, LR: 0.010, Loss: -213.454, NoiseVar: 0.005, SignalVar: 1.724, Lengthscale: 1.498, Epsilon: 0.292\n",
      "Iter: 59, LR: 0.010, Loss: -240.916, NoiseVar: 0.005, SignalVar: 1.719, Lengthscale: 1.508, Epsilon: 0.289\n",
      "Iter: 60, LR: 0.010, Loss: -254.329, NoiseVar: 0.005, SignalVar: 1.714, Lengthscale: 1.519, Epsilon: 0.286\n",
      "Iter: 61, LR: 0.010, Loss: -285.364, NoiseVar: 0.005, SignalVar: 1.710, Lengthscale: 1.529, Epsilon: 0.282\n",
      "Iter: 62, LR: 0.010, Loss: -289.930, NoiseVar: 0.005, SignalVar: 1.705, Lengthscale: 1.540, Epsilon: 0.279\n",
      "Iter: 63, LR: 0.010, Loss: -313.947, NoiseVar: 0.005, SignalVar: 1.700, Lengthscale: 1.550, Epsilon: 0.276\n",
      "Iter: 64, LR: 0.010, Loss: -329.551, NoiseVar: 0.005, SignalVar: 1.695, Lengthscale: 1.561, Epsilon: 0.273\n",
      "Iter: 65, LR: 0.010, Loss: -338.761, NoiseVar: 0.005, SignalVar: 1.690, Lengthscale: 1.572, Epsilon: 0.270\n",
      "Iter: 66, LR: 0.010, Loss: -370.346, NoiseVar: 0.004, SignalVar: 1.684, Lengthscale: 1.582, Epsilon: 0.267\n",
      "Iter: 67, LR: 0.010, Loss: -381.093, NoiseVar: 0.004, SignalVar: 1.679, Lengthscale: 1.593, Epsilon: 0.264\n",
      "Iter: 68, LR: 0.010, Loss: -403.284, NoiseVar: 0.004, SignalVar: 1.674, Lengthscale: 1.603, Epsilon: 0.261\n",
      "Iter: 69, LR: 0.010, Loss: -400.543, NoiseVar: 0.004, SignalVar: 1.669, Lengthscale: 1.614, Epsilon: 0.258\n",
      "Iter: 70, LR: 0.010, Loss: -439.252, NoiseVar: 0.004, SignalVar: 1.664, Lengthscale: 1.624, Epsilon: 0.255\n",
      "Iter: 71, LR: 0.010, Loss: -448.546, NoiseVar: 0.004, SignalVar: 1.659, Lengthscale: 1.634, Epsilon: 0.252\n",
      "Iter: 72, LR: 0.010, Loss: -452.225, NoiseVar: 0.004, SignalVar: 1.654, Lengthscale: 1.645, Epsilon: 0.249\n",
      "Iter: 73, LR: 0.010, Loss: -474.690, NoiseVar: 0.004, SignalVar: 1.650, Lengthscale: 1.655, Epsilon: 0.246\n",
      "Iter: 74, LR: 0.010, Loss: -475.372, NoiseVar: 0.004, SignalVar: 1.646, Lengthscale: 1.665, Epsilon: 0.243\n",
      "Iter: 75, LR: 0.010, Loss: -502.108, NoiseVar: 0.004, SignalVar: 1.642, Lengthscale: 1.676, Epsilon: 0.241\n",
      "Iter: 76, LR: 0.010, Loss: -516.018, NoiseVar: 0.004, SignalVar: 1.639, Lengthscale: 1.686, Epsilon: 0.238\n",
      "Iter: 77, LR: 0.010, Loss: -527.543, NoiseVar: 0.004, SignalVar: 1.636, Lengthscale: 1.696, Epsilon: 0.235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 78, LR: 0.010, Loss: -515.088, NoiseVar: 0.004, SignalVar: 1.635, Lengthscale: 1.706, Epsilon: 0.233\n",
      "Iter: 79, LR: 0.010, Loss: -552.300, NoiseVar: 0.004, SignalVar: 1.635, Lengthscale: 1.716, Epsilon: 0.230\n",
      "Iter: 80, LR: 0.010, Loss: -536.921, NoiseVar: 0.004, SignalVar: 1.635, Lengthscale: 1.726, Epsilon: 0.228\n",
      "Iter: 81, LR: 0.010, Loss: -543.395, NoiseVar: 0.003, SignalVar: 1.637, Lengthscale: 1.736, Epsilon: 0.226\n",
      "Iter: 82, LR: 0.010, Loss: -564.579, NoiseVar: 0.003, SignalVar: 1.640, Lengthscale: 1.746, Epsilon: 0.223\n",
      "Iter: 83, LR: 0.010, Loss: -564.736, NoiseVar: 0.003, SignalVar: 1.645, Lengthscale: 1.756, Epsilon: 0.221\n",
      "Iter: 84, LR: 0.010, Loss: -562.913, NoiseVar: 0.003, SignalVar: 1.651, Lengthscale: 1.766, Epsilon: 0.219\n",
      "Iter: 85, LR: 0.010, Loss: -565.581, NoiseVar: 0.003, SignalVar: 1.659, Lengthscale: 1.776, Epsilon: 0.217\n",
      "Iter: 86, LR: 0.010, Loss: -562.583, NoiseVar: 0.003, SignalVar: 1.668, Lengthscale: 1.785, Epsilon: 0.215\n",
      "Iter: 87, LR: 0.010, Loss: -550.045, NoiseVar: 0.003, SignalVar: 1.678, Lengthscale: 1.795, Epsilon: 0.213\n",
      "Iter: 88, LR: 0.010, Loss: -560.527, NoiseVar: 0.003, SignalVar: 1.689, Lengthscale: 1.804, Epsilon: 0.211\n",
      "Iter: 89, LR: 0.010, Loss: -547.643, NoiseVar: 0.003, SignalVar: 1.702, Lengthscale: 1.813, Epsilon: 0.209\n",
      "Iter: 90, LR: 0.010, Loss: -579.821, NoiseVar: 0.003, SignalVar: 1.715, Lengthscale: 1.823, Epsilon: 0.207\n",
      "Iter: 91, LR: 0.010, Loss: -531.460, NoiseVar: 0.003, SignalVar: 1.729, Lengthscale: 1.832, Epsilon: 0.206\n",
      "Iter: 92, LR: 0.010, Loss: -553.025, NoiseVar: 0.003, SignalVar: 1.744, Lengthscale: 1.841, Epsilon: 0.204\n",
      "Iter: 93, LR: 0.010, Loss: -573.832, NoiseVar: 0.003, SignalVar: 1.759, Lengthscale: 1.850, Epsilon: 0.203\n",
      "Iter: 94, LR: 0.010, Loss: -562.987, NoiseVar: 0.003, SignalVar: 1.775, Lengthscale: 1.858, Epsilon: 0.201\n",
      "Iter: 95, LR: 0.010, Loss: -548.593, NoiseVar: 0.003, SignalVar: 1.791, Lengthscale: 1.867, Epsilon: 0.200\n",
      "Iter: 96, LR: 0.010, Loss: -555.637, NoiseVar: 0.003, SignalVar: 1.808, Lengthscale: 1.876, Epsilon: 0.199\n",
      "Iter: 97, LR: 0.010, Loss: -558.168, NoiseVar: 0.003, SignalVar: 1.825, Lengthscale: 1.884, Epsilon: 0.197\n",
      "Iter: 98, LR: 0.010, Loss: -559.180, NoiseVar: 0.003, SignalVar: 1.842, Lengthscale: 1.892, Epsilon: 0.196\n",
      "Iter: 99, LR: 0.010, Loss: -504.092, NoiseVar: 0.003, SignalVar: 1.860, Lengthscale: 1.900, Epsilon: 0.195\n",
      "Time: 97 sec\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "model.manifold_informed_train(lr=1e-2, iter=100,\n",
    "                              decay_step_size=100, decay_magnitude=1.0, \n",
    "                              norm_step_size=10, norm_rand_vec=100, \n",
    "                              verbose=True, save=False)\n",
    "t1 = time()\n",
    "print(\"Time: %.2g sec\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c816c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6f0dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "likelihood.eval()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d201b909",
   "metadata": {},
   "source": [
    "\n",
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "998d4b89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  tensor(0.0183, device='cuda:0')\n",
      "NLL:  tensor(-1.9455, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    preds_test = likelihood(model(test_x))\n",
    "\n",
    "    mean_test = preds_test.mean\n",
    "        \n",
    "    error = test_y - preds_test.mean\n",
    "    covar = preds_test.lazy_covariance_matrix.evaluate_kernel()\n",
    "    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=error.unsqueeze(-1), logdet=True)\n",
    "    \n",
    "    rmse = (error.square().sum()/test_y.shape[0]).sqrt()\n",
    "    nll = 0.5 * sum([inv_quad, logdet, error.size(-1)* np.log(2 * np.pi)])/test_y.shape[0]\n",
    "    model._clear_cache()\n",
    "    \n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"NLL: \", nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13aa47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
