{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e276dbe",
   "metadata": {},
   "source": [
    "# Manifold GP Supervised Learning via Precision Matrix on 1D Manifold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36444a5",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d17d1f",
   "metadata": {},
   "source": [
    "This notebook provides an example of how to perform Gaussian Process Regression on a 1D manifold. In this example we consider a supervised learning scenario, namely the number of labeled data points is equivalent to the number of the sampled points from the underlying manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e9afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.spatial as ss\n",
    "\n",
    "from time import time\n",
    "\n",
    "from manifold_gp.kernels.riemann_matern_kernel import RiemannMaternKernel\n",
    "from manifold_gp.models.riemann_gp import RiemannGP\n",
    "from gpytorch.priors import NormalPrior, GammaPrior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75701656",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02483bf0",
   "metadata": {},
   "source": [
    "### Load & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af216c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mnist' # ['protein','elevators', 'ctslice', 'mnist']\n",
    "cut = 10000\n",
    "\n",
    "if dataset == 'protein':\n",
    "    data = np.loadtxt('datasets/protein.csv', delimiter=\",\")[:cut]\n",
    "    sampled_x, sampled_y = data[:, 1:], data[:, 0]\n",
    "elif dataset == 'elevators':\n",
    "    data = np.array(loadmat('datasets/elevators.mat')['data'])\n",
    "    sampled_x, sampled_y = data[:, :-1], data[:, -1]\n",
    "elif dataset == 'ctslice':\n",
    "    data = np.loadtxt('datasets/ctslice.csv', delimiter=\",\")[:cut]\n",
    "    sampled_x, sampled_y = data[:, :-1], data[:, -1]\n",
    "elif dataset == 'mnist':\n",
    "    data = np.loadtxt('datasets/mnist.csv')\n",
    "    sampled_x, sampled_y = data[:, 2:], data[:, 1]\n",
    "    torch.manual_seed(1337)\n",
    "    rand_idx = torch.randperm(sampled_x.shape[0])\n",
    "    sampled_x = sampled_x[rand_idx]\n",
    "    sampled_y = sampled_y[rand_idx]\n",
    "    \n",
    "preprocess = False\n",
    "normalize_features = False\n",
    "normalize_labels = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a54caa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preprocess:\n",
    "    # remove coincident points\n",
    "    sampled_x, id_unique = np.unique(sampled_x, axis=0, return_index=True)\n",
    "    sampled_y = sampled_y[id_unique]\n",
    "\n",
    "    # cut between 0.01 and 0.99 quantile of distances\n",
    "    kd_tree = ss.KDTree(sampled_x)\n",
    "    v = kd_tree.query(sampled_x, k=2)[0][:, 1]\n",
    "    idx = np.argsort(v)\n",
    "    percentile_start = int(np.round(idx.shape[0]*0.10))\n",
    "    percentile_end = int(np.round(idx.shape[0]*0.90))\n",
    "    sampled_x = sampled_x[idx[percentile_start:percentile_end], :]\n",
    "    sampled_y = sampled_y[idx[percentile_start:percentile_end]]\n",
    "m = sampled_x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972edfe4",
   "metadata": {},
   "source": [
    "### Trainset & Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4d77e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.2 * m)\n",
    "\n",
    "train_x, train_y = sampled_x[:split], sampled_y[:split]\n",
    "test_x, test_y = sampled_x[split:], sampled_y[split:]\n",
    "\n",
    "train_x = torch.from_numpy(train_x).float()\n",
    "train_y = torch.from_numpy(train_y).float()\n",
    "test_x = torch.from_numpy(test_x).float()\n",
    "test_y = torch.from_numpy(test_y).float()\n",
    "\n",
    "if normalize_features:\n",
    "    mu_x, std_x = train_x.mean(dim=-2, keepdim=True), train_x.std(dim=-2, keepdim=True) + 1e-6\n",
    "    train_x.sub_(mu_x).div_(std_x)\n",
    "    test_x.sub_(mu_x).div_(std_x)\n",
    "    \n",
    "if normalize_labels:\n",
    "    mu_y, std_y = train_y.mean(), train_y.std()\n",
    "    train_y.sub_(mu_y).div_(std_y)\n",
    "    test_y.sub_(mu_y).div_(std_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec761d",
   "metadata": {},
   "source": [
    "### Hyperparameters Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18015f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial as ss\n",
    "neighbors = 10\n",
    "kd_tree = ss.KDTree(train_x)\n",
    "v = np.sort(kd_tree.query(train_x, k=neighbors+1)[0][:, 1:].ravel())\n",
    "percentile_99 = int(np.round(v.shape[0]*0.99))\n",
    "gamma_rate = 100.0/np.std(v)\n",
    "gamma_concentration = gamma_rate * v[percentile_99] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87581de",
   "metadata": {},
   "source": [
    "### Move Data to Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c91b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train_x.contiguous(), train_y.contiguous()\n",
    "test_x, test_y = test_x.contiguous(), test_y.contiguous()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "train_x, train_y = train_x.to(device), train_y.to(device)\n",
    "test_x, test_y = test_x.to(device), test_y.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d4275",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83460075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(\n",
    "    noise_constraint=gpytorch.constraints.GreaterThan(1e-8),\n",
    "    noise_prior=None  # NormalPrior(torch.tensor([0.0]).to(device),  torch.tensor([1/9]).sqrt().to(device))\n",
    ")\n",
    "\n",
    "kernel = gpytorch.kernels.ScaleKernel(\n",
    "    RiemannMaternKernel(\n",
    "        nu=3,\n",
    "        nodes=train_x,\n",
    "        neighbors=50,\n",
    "        operator=\"randomwalk\",\n",
    "        modes=100,\n",
    "        ball_scale=10.0,\n",
    "        support_kernel=gpytorch.kernels.RBFKernel(),\n",
    "        epsilon_prior=GammaPrior(gamma_concentration, gamma_rate),\n",
    "        lengthscale_prior=None  # InverseGammaPrior(igamma_concentration, igamma_rate)\n",
    "    ),\n",
    "    outputscale_prior=None  # NormalPrior(torch.tensor([1.0]).to(device),  torch.tensor([1/9]).sqrt().to(device))\n",
    ")\n",
    "\n",
    "model = RiemannGP(train_x, train_y, likelihood, kernel).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14763b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357e1dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "hypers = {\n",
    "    'likelihood.noise_covar.noise': 1e-2,\n",
    "    'covar_module.base_kernel.epsilon': 0.5,\n",
    "    'covar_module.base_kernel.lengthscale': 0.5,\n",
    "    'covar_module.outputscale': 1.0,\n",
    "    'covar_module.base_kernel.support_kernel.lengthscale': 1.0,\n",
    "}\n",
    "model.initialize(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb0ab30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, LR: 0.010, Loss: 2516.284, NoiseVar: 0.010, SignalVar: 506084.750, Lengthscale: 0.500, Epsilon: 0.500\n",
      "Iter: 1, LR: 0.010, Loss: 2450.665, NoiseVar: 0.010, SignalVar: 506084.750, Lengthscale: 0.496, Epsilon: 0.496\n",
      "Iter: 2, LR: 0.010, Loss: 2401.370, NoiseVar: 0.010, SignalVar: 506084.750, Lengthscale: 0.492, Epsilon: 0.492\n",
      "Iter: 3, LR: 0.010, Loss: 2364.167, NoiseVar: 0.010, SignalVar: 506084.750, Lengthscale: 0.488, Epsilon: 0.488\n",
      "Iter: 4, LR: 0.010, Loss: 2322.110, NoiseVar: 0.010, SignalVar: 506084.750, Lengthscale: 0.485, Epsilon: 0.484\n",
      "Iter: 5, LR: 0.010, Loss: 2286.550, NoiseVar: 0.010, SignalVar: 506084.750, Lengthscale: 0.481, Epsilon: 0.481\n",
      "Iter: 6, LR: 0.010, Loss: 2258.339, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.478, Epsilon: 0.477\n",
      "Iter: 7, LR: 0.010, Loss: 2241.546, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.474, Epsilon: 0.473\n",
      "Iter: 8, LR: 0.010, Loss: 2211.733, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.472, Epsilon: 0.469\n",
      "Iter: 9, LR: 0.010, Loss: 2192.603, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.469, Epsilon: 0.465\n",
      "Iter: 10, LR: 0.010, Loss: 2171.256, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.467, Epsilon: 0.461\n",
      "Iter: 11, LR: 0.010, Loss: 2156.056, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.465, Epsilon: 0.458\n",
      "Iter: 12, LR: 0.010, Loss: 2137.030, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.464, Epsilon: 0.454\n",
      "Iter: 13, LR: 0.010, Loss: 2108.861, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.464, Epsilon: 0.450\n",
      "Iter: 14, LR: 0.010, Loss: 2077.734, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.463, Epsilon: 0.446\n",
      "Iter: 15, LR: 0.010, Loss: 2054.384, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.463, Epsilon: 0.442\n",
      "Iter: 16, LR: 0.010, Loss: 2034.288, NoiseVar: 0.009, SignalVar: 506084.750, Lengthscale: 0.464, Epsilon: 0.439\n",
      "Iter: 17, LR: 0.010, Loss: 1997.368, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.464, Epsilon: 0.435\n",
      "Iter: 18, LR: 0.010, Loss: 1977.982, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.465, Epsilon: 0.431\n",
      "Iter: 19, LR: 0.010, Loss: 1948.790, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.466, Epsilon: 0.427\n",
      "Iter: 20, LR: 0.010, Loss: 1918.934, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.466, Epsilon: 0.424\n",
      "Iter: 21, LR: 0.010, Loss: 1891.671, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.467, Epsilon: 0.420\n",
      "Iter: 22, LR: 0.010, Loss: 1865.598, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.468, Epsilon: 0.416\n",
      "Iter: 23, LR: 0.010, Loss: 1850.095, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.468, Epsilon: 0.413\n",
      "Iter: 24, LR: 0.010, Loss: 1807.531, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.468, Epsilon: 0.409\n",
      "Iter: 25, LR: 0.010, Loss: 1782.996, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.469, Epsilon: 0.406\n",
      "Iter: 26, LR: 0.010, Loss: 1758.075, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.468, Epsilon: 0.402\n",
      "Iter: 27, LR: 0.010, Loss: 1716.945, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.468, Epsilon: 0.398\n",
      "Iter: 28, LR: 0.010, Loss: 1698.043, NoiseVar: 0.008, SignalVar: 506084.750, Lengthscale: 0.468, Epsilon: 0.395\n",
      "Iter: 29, LR: 0.010, Loss: 1665.019, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.467, Epsilon: 0.391\n",
      "Iter: 30, LR: 0.010, Loss: 1633.947, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.466, Epsilon: 0.388\n",
      "Iter: 31, LR: 0.010, Loss: 1596.826, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.466, Epsilon: 0.384\n",
      "Iter: 32, LR: 0.010, Loss: 1569.924, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.465, Epsilon: 0.381\n",
      "Iter: 33, LR: 0.010, Loss: 1530.812, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.464, Epsilon: 0.377\n",
      "Iter: 34, LR: 0.010, Loss: 1486.427, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.463, Epsilon: 0.374\n",
      "Iter: 35, LR: 0.010, Loss: 1467.702, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.462, Epsilon: 0.370\n",
      "Iter: 36, LR: 0.010, Loss: 1431.776, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.461, Epsilon: 0.367\n",
      "Iter: 37, LR: 0.010, Loss: 1389.954, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.460, Epsilon: 0.364\n",
      "Iter: 38, LR: 0.010, Loss: 1347.699, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.459, Epsilon: 0.360\n",
      "Iter: 39, LR: 0.010, Loss: 1321.874, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.458, Epsilon: 0.357\n",
      "Iter: 40, LR: 0.010, Loss: 1280.136, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.457, Epsilon: 0.353\n",
      "Iter: 41, LR: 0.010, Loss: 1238.113, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.457, Epsilon: 0.350\n",
      "Iter: 42, LR: 0.010, Loss: 1196.299, NoiseVar: 0.007, SignalVar: 506084.750, Lengthscale: 0.456, Epsilon: 0.346\n",
      "Iter: 43, LR: 0.010, Loss: 1160.776, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.456, Epsilon: 0.343\n",
      "Iter: 44, LR: 0.010, Loss: 1110.023, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.456, Epsilon: 0.340\n",
      "Iter: 45, LR: 0.010, Loss: 1079.748, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.455, Epsilon: 0.336\n",
      "Iter: 46, LR: 0.010, Loss: 1024.840, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.455, Epsilon: 0.333\n",
      "Iter: 47, LR: 0.010, Loss: 986.635, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.455, Epsilon: 0.329\n",
      "Iter: 48, LR: 0.010, Loss: 942.235, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.455, Epsilon: 0.326\n",
      "Iter: 49, LR: 0.010, Loss: 901.105, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.455, Epsilon: 0.323\n",
      "Iter: 50, LR: 0.010, Loss: 843.088, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.455, Epsilon: 0.319\n",
      "Iter: 51, LR: 0.010, Loss: 799.306, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.455, Epsilon: 0.316\n",
      "Iter: 52, LR: 0.010, Loss: 744.863, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.454, Epsilon: 0.313\n",
      "Iter: 53, LR: 0.010, Loss: 691.613, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.454, Epsilon: 0.309\n",
      "Iter: 54, LR: 0.010, Loss: 652.119, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.454, Epsilon: 0.306\n",
      "Iter: 55, LR: 0.010, Loss: 588.104, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.453, Epsilon: 0.303\n",
      "Iter: 56, LR: 0.010, Loss: 540.352, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.453, Epsilon: 0.300\n",
      "Iter: 57, LR: 0.010, Loss: 478.370, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.452, Epsilon: 0.296\n",
      "Iter: 58, LR: 0.010, Loss: 425.948, NoiseVar: 0.006, SignalVar: 506084.750, Lengthscale: 0.452, Epsilon: 0.293\n",
      "Iter: 59, LR: 0.010, Loss: 372.553, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.451, Epsilon: 0.290\n",
      "Iter: 60, LR: 0.010, Loss: 309.509, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.451, Epsilon: 0.287\n",
      "Iter: 61, LR: 0.010, Loss: 234.862, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.450, Epsilon: 0.283\n",
      "Iter: 62, LR: 0.010, Loss: 186.524, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.450, Epsilon: 0.280\n",
      "Iter: 63, LR: 0.010, Loss: 128.120, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.449, Epsilon: 0.277\n",
      "Iter: 64, LR: 0.010, Loss: 55.886, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.449, Epsilon: 0.274\n",
      "Iter: 65, LR: 0.010, Loss: 5.224, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.449, Epsilon: 0.271\n",
      "Iter: 66, LR: 0.010, Loss: -72.922, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.448, Epsilon: 0.268\n",
      "Iter: 67, LR: 0.010, Loss: -131.208, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.448, Epsilon: 0.265\n",
      "Iter: 68, LR: 0.010, Loss: -219.979, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.448, Epsilon: 0.261\n",
      "Iter: 69, LR: 0.010, Loss: -278.224, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.447, Epsilon: 0.258\n",
      "Iter: 70, LR: 0.010, Loss: -366.380, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.447, Epsilon: 0.255\n",
      "Iter: 71, LR: 0.010, Loss: -423.177, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.447, Epsilon: 0.252\n",
      "Iter: 72, LR: 0.010, Loss: -498.320, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.446, Epsilon: 0.249\n",
      "Iter: 73, LR: 0.010, Loss: -574.602, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.446, Epsilon: 0.246\n",
      "Iter: 74, LR: 0.010, Loss: -674.780, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.446, Epsilon: 0.243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 75, LR: 0.010, Loss: -741.925, NoiseVar: 0.005, SignalVar: 506084.750, Lengthscale: 0.445, Epsilon: 0.240\n",
      "Iter: 76, LR: 0.010, Loss: -819.318, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.445, Epsilon: 0.237\n",
      "Iter: 77, LR: 0.010, Loss: -904.576, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.445, Epsilon: 0.234\n",
      "Iter: 78, LR: 0.010, Loss: -977.281, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.445, Epsilon: 0.231\n",
      "Iter: 79, LR: 0.010, Loss: -1068.922, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.444, Epsilon: 0.228\n",
      "Iter: 80, LR: 0.010, Loss: -1157.965, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.444, Epsilon: 0.225\n",
      "Iter: 81, LR: 0.010, Loss: -1252.804, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.444, Epsilon: 0.223\n",
      "Iter: 82, LR: 0.010, Loss: -1342.838, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.443, Epsilon: 0.220\n",
      "Iter: 83, LR: 0.010, Loss: -1435.137, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.443, Epsilon: 0.217\n",
      "Iter: 84, LR: 0.010, Loss: -1534.787, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.443, Epsilon: 0.214\n",
      "Iter: 85, LR: 0.010, Loss: -1637.236, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.443, Epsilon: 0.211\n",
      "Iter: 86, LR: 0.010, Loss: -1742.456, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.442, Epsilon: 0.209\n",
      "Iter: 87, LR: 0.010, Loss: -1835.785, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.442, Epsilon: 0.206\n",
      "Iter: 88, LR: 0.010, Loss: -1947.703, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.442, Epsilon: 0.203\n",
      "Iter: 89, LR: 0.010, Loss: -2040.669, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.442, Epsilon: 0.200\n",
      "Iter: 90, LR: 0.010, Loss: -2160.729, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.441, Epsilon: 0.198\n",
      "Iter: 91, LR: 0.010, Loss: -2266.381, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.441, Epsilon: 0.195\n",
      "Iter: 92, LR: 0.010, Loss: -2387.237, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.441, Epsilon: 0.192\n",
      "Iter: 93, LR: 0.010, Loss: -2504.291, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.441, Epsilon: 0.190\n",
      "Iter: 94, LR: 0.010, Loss: -2607.244, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.441, Epsilon: 0.187\n",
      "Iter: 95, LR: 0.010, Loss: -2733.509, NoiseVar: 0.004, SignalVar: 506084.750, Lengthscale: 0.441, Epsilon: 0.185\n",
      "Iter: 96, LR: 0.010, Loss: -2858.206, NoiseVar: 0.003, SignalVar: 506084.750, Lengthscale: 0.440, Epsilon: 0.182\n",
      "Iter: 97, LR: 0.010, Loss: -2994.372, NoiseVar: 0.003, SignalVar: 506084.750, Lengthscale: 0.440, Epsilon: 0.179\n",
      "Iter: 98, LR: 0.010, Loss: -3101.502, NoiseVar: 0.003, SignalVar: 506084.750, Lengthscale: 0.440, Epsilon: 0.177\n",
      "Iter: 99, LR: 0.010, Loss: -3250.297, NoiseVar: 0.003, SignalVar: 506084.750, Lengthscale: 0.440, Epsilon: 0.174\n",
      "Time: 10 sec\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "model.manifold_informed_train(lr=1e-2, iter=100, norm_step_size=1000, num_rand_vec=500, verbose=True)\n",
    "t1 = time()\n",
    "print(\"Time: %.2g sec\" % (t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab36075",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "998d4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "likelihood.eval()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c57771",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40ffbd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  tensor(0.0065, device='cuda:0')\n",
      "NLL:  tensor(-1.5491, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(), gpytorch.settings.fast_pred_var(), gpytorch.settings.cg_tolerance(10000):\n",
    "    preds_test = likelihood(model(test_x))\n",
    "        \n",
    "    error = test_y - preds_test.mean\n",
    "    covar = preds_test.lazy_covariance_matrix.evaluate_kernel()\n",
    "    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=error.unsqueeze(-1), logdet=True)\n",
    "    \n",
    "    rmse = (error.square().sum()/test_y.shape[0]).sqrt()\n",
    "    nll = 0.5 * sum([inv_quad, logdet, error.size(-1)* np.log(2 * np.pi)])/test_y.shape[0]\n",
    "    model._clear_cache()\n",
    "    \n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"NLL: \", nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b1b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
