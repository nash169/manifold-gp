{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e276dbe",
   "metadata": {},
   "source": [
    "# IMGP - Semisupervised Learning - 1D Manifold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36444a5",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d17d1f",
   "metadata": {},
   "source": [
    "This notebook provides an example of how to perform Gaussian Process Regression on a 1D manifold. In this example we consider a supervised learning scenario, namely the number of labeled data points is equivalent to the number of the sampled points from the underlying manifold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e9afd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "\n",
    "from manifold_gp.kernels.riemann_matern_kernel import RiemannMaternKernel\n",
    "from manifold_gp.models import RiemannGP, VanillaGP\n",
    "from manifold_gp.utils import rmnist_dataset, vanilla_train, manifold_informed_train, test_model, NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a13054",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b260ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 0.1\n",
    "scaling, single_digit, regenerate = True, True, False, \n",
    "normalize_x, normalize_y = False, True\n",
    "graphbandwidth_constraint, graphbandwidth_prior = False, False\n",
    "load_manifold_model, load_vanilla_model = False, False\n",
    "train_manifold_model, train_vanilla_model = True, True\n",
    "save_manifold_model, save_vanilla_model = True, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af216c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled_x, sampled_y, _, test_x, test_y, _ = rmnist_dataset(scaling=scaling, single_digit=single_digit, regenerate=regenerate)\n",
    "# torch.manual_seed(1337)\n",
    "# train_idx = torch.zeros(sampled_x.shape[0]).scatter_(0, torch.randperm(sampled_x.shape[0])[:int(num_train*sampled_x.shape[0])], 1).bool()\n",
    "sampled_x, sampled_y = torch.from_numpy(np.load('../datasets/srmnist_train_x.npy')).float(), torch.from_numpy(np.load('../datasets/srmnist_train_y.npy')).float()\n",
    "test_x, test_y = torch.from_numpy(np.load('../datasets/srmnist_test_x.npy')).float(), torch.from_numpy(np.load('../datasets/srmnist_test_y.npy')).float()\n",
    "torch.manual_seed(1337)\n",
    "rand_idx = torch.randperm(sampled_x.shape[0])\n",
    "sampled_x, sampled_y = sampled_x[rand_idx], sampled_y[rand_idx]\n",
    "train_idx = torch.zeros(sampled_x.shape[0]).scatter_(0, torch.arange(0, int(num_train*sampled_x.shape[0])), 1).bool()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "sampled_x, sampled_y = sampled_x.contiguous().to(device).flatten(start_dim=1), sampled_y.contiguous().to(device)\n",
    "train_x, train_y = sampled_x[train_idx], sampled_y[train_idx]\n",
    "test_x, test_y = test_x.contiguous().to(device).flatten(start_dim=1), test_y.contiguous().to(device)\n",
    "    \n",
    "if normalize_x:\n",
    "    mu_x, std_x = sampled_x.mean(dim=-2, keepdim=True), sampled_x.std(dim=-2, keepdim=True) + 1e-6\n",
    "    sampled_x.sub_(mu_x).div_(std_x)\n",
    "    train_x.sub_(mu_x).div_(std_x)\n",
    "    test_x.sub_(mu_x).div_(std_x)\n",
    "if normalize_y:\n",
    "    mu_y, std_y = train_y.mean(), train_y.std()\n",
    "    sampled_y.sub_(mu_y).div_(std_y)\n",
    "    train_y.sub_(mu_y).div_(std_y)\n",
    "    test_y.sub_(mu_y).div_(std_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d608c26f-42d3-4d4d-bcd1-87a15f182243",
   "metadata": {},
   "outputs": [],
   "source": [
    "if graphbandwidth_constraint or graphbandwidth_prior:\n",
    "    knn = NearestNeighbors(sampled_x, nlist=1)\n",
    "    edge_values = knn.search(sampled_x, 10)[0][:, 1:]\n",
    "    \n",
    "    graphbandwidth_min = edge_values[:,0].max().div(-4*math.log(1e-4)).sqrt()\n",
    "    median = edge_values.sqrt().mean(dim=1).sort()[0][int(round(edge_values.shape[0]*0.50))]\n",
    "    gamma_rate = 4*median/(median-graphbandwidth_min)**2\n",
    "    gamma_concentration = gamma_rate * median + 1\n",
    "    \n",
    "    del knn, edge_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405d4275",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f219323b-13b5-48f2-8f8b-5bcd6c07b1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model_vanilla = VanillaGP(\n",
    "    train_x, \n",
    "    train_y, \n",
    "    gpytorch.likelihoods.GaussianLikelihood(), \n",
    "    gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    # gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=2.5))\n",
    ").to(device)\n",
    "\n",
    "hypers_vanilla = {\n",
    "    'likelihood.noise_covar.noise': 1e-2,\n",
    "    'covar_module.base_kernel.lengthscale': 1.0,\n",
    "    'covar_module.outputscale': 1.0,\n",
    "}\n",
    "model_vanilla.initialize(**hypers_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83460075",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(\n",
    "    noise_constraint=gpytorch.constraints.GreaterThan(1e-8),\n",
    ")\n",
    "\n",
    "kernel = gpytorch.kernels.ScaleKernel(\n",
    "    RiemannMaternKernel(\n",
    "        nu=2,\n",
    "        x=sampled_x,\n",
    "        nearest_neighbors=50,\n",
    "        laplacian_normalization=\"randomwalk\",\n",
    "        num_modes=100,\n",
    "        bump_scale=10.0,\n",
    "        bump_decay=0.01,\n",
    "        graphbandwidth_constraint=gpytorch.constraints.GreaterThan(graphbandwidth_min) if graphbandwidth_constraint else None,\n",
    "        graphbandwidth_prior=gpytorch.priors.GammaPrior(gamma_concentration, gamma_rate) if graphbandwidth_prior else None\n",
    "    )\n",
    ")\n",
    "\n",
    "model = RiemannGP(train_x, train_y, likelihood, kernel, train_idx).to(device)\n",
    "\n",
    "hypers = {\n",
    "    'likelihood.noise_covar.noise': 1e-2,\n",
    "    'covar_module.base_kernel.graphbandwidth': kernel.base_kernel.graphbandwidth_prior.sample() if graphbandwidth_prior else 0.5,\n",
    "    'covar_module.base_kernel.lengthscale': 1.0,\n",
    "    'covar_module.outputscale': 1.0,\n",
    "}\n",
    "model.initialize(**hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b14763b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b840d4c-68c2-40b0-bccd-d8e31e1b8489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernardo/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:46: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: 1823.060, Lr: 0.05,\tNoise Variance: 0.010,\tSignal Variance: 1.944,\tLengthscale: 1.000, Graphbandwidth: 0.500\n",
      "Iteration: 1, Loss: 1653.545, Lr: 0.05,\tNoise Variance: 0.011,\tSignal Variance: 1.901,\tLengthscale: 1.032, Graphbandwidth: 0.520\n",
      "Iteration: 2, Loss: 1530.147, Lr: 0.05,\tNoise Variance: 0.011,\tSignal Variance: 1.860,\tLengthscale: 1.064, Graphbandwidth: 0.540\n",
      "Iteration: 3, Loss: 1446.220, Lr: 0.05,\tNoise Variance: 0.012,\tSignal Variance: 1.820,\tLengthscale: 1.095, Graphbandwidth: 0.560\n",
      "Iteration: 4, Loss: 1387.778, Lr: 0.05,\tNoise Variance: 0.012,\tSignal Variance: 1.781,\tLengthscale: 1.126, Graphbandwidth: 0.579\n",
      "Iteration: 5, Loss: 1355.738, Lr: 0.05,\tNoise Variance: 0.012,\tSignal Variance: 1.746,\tLengthscale: 1.156, Graphbandwidth: 0.597\n",
      "Iteration: 6, Loss: 1337.880, Lr: 0.05,\tNoise Variance: 0.013,\tSignal Variance: 1.713,\tLengthscale: 1.184, Graphbandwidth: 0.613\n",
      "Iteration: 7, Loss: 1331.481, Lr: 0.05,\tNoise Variance: 0.013,\tSignal Variance: 1.683,\tLengthscale: 1.211, Graphbandwidth: 0.627\n",
      "Iteration: 8, Loss: 1332.210, Lr: 0.05,\tNoise Variance: 0.014,\tSignal Variance: 1.657,\tLengthscale: 1.236, Graphbandwidth: 0.639\n",
      "Iteration: 9, Loss: 1334.162, Lr: 0.05,\tNoise Variance: 0.014,\tSignal Variance: 1.634,\tLengthscale: 1.258, Graphbandwidth: 0.648\n",
      "Iteration: 10, Loss: 1338.118, Lr: 0.05,\tNoise Variance: 0.014,\tSignal Variance: 1.615,\tLengthscale: 1.279, Graphbandwidth: 0.655\n",
      "Iteration: 11, Loss: 1344.397, Lr: 0.05,\tNoise Variance: 0.014,\tSignal Variance: 1.599,\tLengthscale: 1.298, Graphbandwidth: 0.660\n",
      "Iteration: 12, Loss: 1347.574, Lr: 0.05,\tNoise Variance: 0.015,\tSignal Variance: 1.587,\tLengthscale: 1.314, Graphbandwidth: 0.662\n",
      "Iteration: 13, Loss: 1353.487, Lr: 0.05,\tNoise Variance: 0.015,\tSignal Variance: 1.578,\tLengthscale: 1.329, Graphbandwidth: 0.662\n",
      "Iteration: 14, Loss: 1352.480, Lr: 0.05,\tNoise Variance: 0.015,\tSignal Variance: 1.572,\tLengthscale: 1.341, Graphbandwidth: 0.660\n",
      "Iteration: 15, Loss: 1351.793, Lr: 0.05,\tNoise Variance: 0.015,\tSignal Variance: 1.569,\tLengthscale: 1.352, Graphbandwidth: 0.656\n",
      "Iteration: 16, Loss: 1348.890, Lr: 0.05,\tNoise Variance: 0.015,\tSignal Variance: 1.569,\tLengthscale: 1.362, Graphbandwidth: 0.650\n",
      "Iteration: 17, Loss: 1338.749, Lr: 0.05,\tNoise Variance: 0.015,\tSignal Variance: 1.571,\tLengthscale: 1.370, Graphbandwidth: 0.643\n",
      "Iteration: 18, Loss: 1330.397, Lr: 0.05,\tNoise Variance: 0.015,\tSignal Variance: 1.575,\tLengthscale: 1.377, Graphbandwidth: 0.634\n",
      "Iteration: 19, Loss: 1320.708, Lr: 0.05,\tNoise Variance: 0.015,\tSignal Variance: 1.581,\tLengthscale: 1.383, Graphbandwidth: 0.625\n",
      "Iteration: 20, Loss: 1309.231, Lr: 0.05,\tNoise Variance: 0.015,\tSignal Variance: 1.588,\tLengthscale: 1.389, Graphbandwidth: 0.614\n",
      "Iteration: 21, Loss: 1297.746, Lr: 0.05,\tNoise Variance: 0.015,\tSignal Variance: 1.597,\tLengthscale: 1.393, Graphbandwidth: 0.602\n",
      "Iteration: 22, Loss: 1286.557, Lr: 0.05,\tNoise Variance: 0.014,\tSignal Variance: 1.607,\tLengthscale: 1.398, Graphbandwidth: 0.590\n",
      "Iteration: 23, Loss: 1270.154, Lr: 0.05,\tNoise Variance: 0.014,\tSignal Variance: 1.617,\tLengthscale: 1.402, Graphbandwidth: 0.577\n",
      "Iteration: 24, Loss: 1257.073, Lr: 0.05,\tNoise Variance: 0.014,\tSignal Variance: 1.628,\tLengthscale: 1.407, Graphbandwidth: 0.564\n",
      "Iteration: 25, Loss: 1244.120, Lr: 0.05,\tNoise Variance: 0.014,\tSignal Variance: 1.639,\tLengthscale: 1.412, Graphbandwidth: 0.550\n",
      "Iteration: 26, Loss: 1228.221, Lr: 0.05,\tNoise Variance: 0.014,\tSignal Variance: 1.650,\tLengthscale: 1.418, Graphbandwidth: 0.537\n",
      "Iteration: 27, Loss: 1211.046, Lr: 0.05,\tNoise Variance: 0.014,\tSignal Variance: 1.661,\tLengthscale: 1.425, Graphbandwidth: 0.523\n",
      "Iteration: 28, Loss: 1198.439, Lr: 0.05,\tNoise Variance: 0.013,\tSignal Variance: 1.670,\tLengthscale: 1.433, Graphbandwidth: 0.509\n",
      "Iteration: 29, Loss: 1181.834, Lr: 0.05,\tNoise Variance: 0.013,\tSignal Variance: 1.679,\tLengthscale: 1.443, Graphbandwidth: 0.496\n",
      "Iteration: 30, Loss: 1163.736, Lr: 0.05,\tNoise Variance: 0.013,\tSignal Variance: 1.686,\tLengthscale: 1.454, Graphbandwidth: 0.482\n",
      "Iteration: 31, Loss: 1142.818, Lr: 0.05,\tNoise Variance: 0.013,\tSignal Variance: 1.692,\tLengthscale: 1.468, Graphbandwidth: 0.469\n",
      "Iteration: 32, Loss: 1123.293, Lr: 0.05,\tNoise Variance: 0.013,\tSignal Variance: 1.696,\tLengthscale: 1.483, Graphbandwidth: 0.456\n",
      "Iteration: 33, Loss: 1097.076, Lr: 0.05,\tNoise Variance: 0.012,\tSignal Variance: 1.697,\tLengthscale: 1.501, Graphbandwidth: 0.444\n",
      "Iteration: 34, Loss: 1073.639, Lr: 0.05,\tNoise Variance: 0.012,\tSignal Variance: 1.697,\tLengthscale: 1.521, Graphbandwidth: 0.431\n",
      "Iteration: 35, Loss: 1037.631, Lr: 0.05,\tNoise Variance: 0.012,\tSignal Variance: 1.695,\tLengthscale: 1.544, Graphbandwidth: 0.419\n",
      "Iteration: 36, Loss: 1002.113, Lr: 0.05,\tNoise Variance: 0.011,\tSignal Variance: 1.691,\tLengthscale: 1.569, Graphbandwidth: 0.406\n",
      "Iteration: 37, Loss: 963.112, Lr: 0.05,\tNoise Variance: 0.011,\tSignal Variance: 1.685,\tLengthscale: 1.596, Graphbandwidth: 0.394\n",
      "Iteration: 38, Loss: 914.447, Lr: 0.05,\tNoise Variance: 0.011,\tSignal Variance: 1.677,\tLengthscale: 1.625, Graphbandwidth: 0.381\n",
      "Iteration: 39, Loss: 858.369, Lr: 0.05,\tNoise Variance: 0.010,\tSignal Variance: 1.668,\tLengthscale: 1.657, Graphbandwidth: 0.369\n",
      "Iteration: 40, Loss: 812.448, Lr: 0.05,\tNoise Variance: 0.010,\tSignal Variance: 1.657,\tLengthscale: 1.691, Graphbandwidth: 0.356\n",
      "Iteration: 41, Loss: 750.844, Lr: 0.05,\tNoise Variance: 0.010,\tSignal Variance: 1.644,\tLengthscale: 1.727, Graphbandwidth: 0.343\n",
      "Iteration: 42, Loss: 694.185, Lr: 0.05,\tNoise Variance: 0.009,\tSignal Variance: 1.631,\tLengthscale: 1.764, Graphbandwidth: 0.330\n",
      "Iteration: 43, Loss: 625.801, Lr: 0.05,\tNoise Variance: 0.009,\tSignal Variance: 1.617,\tLengthscale: 1.803, Graphbandwidth: 0.317\n",
      "Iteration: 44, Loss: 555.270, Lr: 0.05,\tNoise Variance: 0.008,\tSignal Variance: 1.603,\tLengthscale: 1.843, Graphbandwidth: 0.304\n",
      "Iteration: 45, Loss: 486.180, Lr: 0.05,\tNoise Variance: 0.008,\tSignal Variance: 1.589,\tLengthscale: 1.884, Graphbandwidth: 0.291\n",
      "Iteration: 46, Loss: 402.114, Lr: 0.05,\tNoise Variance: 0.007,\tSignal Variance: 1.575,\tLengthscale: 1.926, Graphbandwidth: 0.278\n",
      "Iteration: 47, Loss: 309.585, Lr: 0.05,\tNoise Variance: 0.007,\tSignal Variance: 1.560,\tLengthscale: 1.969, Graphbandwidth: 0.266\n",
      "Iteration: 48, Loss: 250.322, Lr: 0.05,\tNoise Variance: 0.006,\tSignal Variance: 1.546,\tLengthscale: 2.012, Graphbandwidth: 0.253\n",
      "Iteration: 49, Loss: 167.980, Lr: 0.05,\tNoise Variance: 0.006,\tSignal Variance: 1.531,\tLengthscale: 2.055, Graphbandwidth: 0.242\n",
      "Iteration: 50, Loss: 95.532, Lr: 0.05,\tNoise Variance: 0.005,\tSignal Variance: 1.515,\tLengthscale: 2.099, Graphbandwidth: 0.230\n",
      "Iteration: 51, Loss: 16.793, Lr: 0.05,\tNoise Variance: 0.005,\tSignal Variance: 1.499,\tLengthscale: 2.142, Graphbandwidth: 0.219\n",
      "Iteration: 52, Loss: -52.627, Lr: 0.05,\tNoise Variance: 0.005,\tSignal Variance: 1.481,\tLengthscale: 2.185, Graphbandwidth: 0.209\n",
      "Iteration: 53, Loss: -109.835, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.461,\tLengthscale: 2.228, Graphbandwidth: 0.200\n",
      "Iteration: 54, Loss: -166.488, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.438,\tLengthscale: 2.270, Graphbandwidth: 0.192\n",
      "Iteration: 55, Loss: -211.196, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.412,\tLengthscale: 2.312, Graphbandwidth: 0.185\n",
      "Iteration: 56, Loss: -285.158, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.382,\tLengthscale: 2.353, Graphbandwidth: 0.179\n",
      "Iteration: 57, Loss: -312.422, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.347,\tLengthscale: 2.393, Graphbandwidth: 0.175\n",
      "Iteration: 58, Loss: -314.130, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.310,\tLengthscale: 2.433, Graphbandwidth: 0.171\n",
      "Iteration: 59, Loss: -346.807, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.270,\tLengthscale: 2.471, Graphbandwidth: 0.169\n",
      "Iteration: 60, Loss: -357.864, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.227,\tLengthscale: 2.508, Graphbandwidth: 0.167\n",
      "Iteration: 61, Loss: -369.296, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.184,\tLengthscale: 2.544, Graphbandwidth: 0.166\n",
      "Iteration: 62, Loss: -348.465, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.139,\tLengthscale: 2.578, Graphbandwidth: 0.166\n",
      "Iteration: 63, Loss: -360.673, Lr: 0.05,\tNoise Variance: 0.004,\tSignal Variance: 1.095,\tLengthscale: 2.611, Graphbandwidth: 0.166\n",
      "Iteration: 64, Loss: -341.201, Lr: 0.05,\tNoise Variance: 0.005,\tSignal Variance: 1.052,\tLengthscale: 2.642, Graphbandwidth: 0.166\n",
      "Iteration: 65, Loss: -333.776, Lr: 0.05,\tNoise Variance: 0.005,\tSignal Variance: 1.009,\tLengthscale: 2.671, Graphbandwidth: 0.166\n",
      "Iteration: 66, Loss: -334.542, Lr: 0.05,\tNoise Variance: 0.005,\tSignal Variance: 0.968,\tLengthscale: 2.699, Graphbandwidth: 0.166\n",
      "Iteration: 67, Loss: -340.001, Lr: 0.05,\tNoise Variance: 0.006,\tSignal Variance: 0.929,\tLengthscale: 2.725, Graphbandwidth: 0.165\n",
      "Iteration: 68, Loss: -315.685, Lr: 0.05,\tNoise Variance: 0.006,\tSignal Variance: 0.894,\tLengthscale: 2.749, Graphbandwidth: 0.163\n",
      "Iteration: 69, Loss: -340.221, Lr: 0.05,\tNoise Variance: 0.007,\tSignal Variance: 0.860,\tLengthscale: 2.771, Graphbandwidth: 0.161\n",
      "Iteration: 70, Loss: -388.352, Lr: 0.05,\tNoise Variance: 0.007,\tSignal Variance: 0.830,\tLengthscale: 2.792, Graphbandwidth: 0.158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.188089057803154 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 71, Loss: -416.178, Lr: 0.05,\tNoise Variance: 0.008,\tSignal Variance: 0.803,\tLengthscale: 2.811, Graphbandwidth: 0.154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 2.5282273292541504 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 72, Loss: -532.160, Lr: 0.05,\tNoise Variance: 0.009,\tSignal Variance: 0.783,\tLengthscale: 2.829, Graphbandwidth: 0.149\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_41488/2214138955.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50, threshold=1e-3, threshold_mode='rel',\n\u001b[1;32m      7\u001b[0m                                                            cooldown=0, min_lr=0, eps=1e-8, verbose=True)\n\u001b[0;32m----> 8\u001b[0;31m     loss = manifold_informed_train(model, optimizer, max_iter=100, tolerance=1e-2, update_norm=None, num_rand_vec=100,\n\u001b[0m\u001b[1;32m      9\u001b[0m                                    max_cholesky=1000, cg_tolerance=1e-2, cg_max_iter=1000, scheduler=scheduler, verbose=True)\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_manifold_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/manifold_gp/utils/train_model.py\u001b[0m in \u001b[0;36mmanifold_informed_train\u001b[0;34m(model, optimizer, max_iter, tolerance, update_norm, num_rand_vec, max_cholesky, cg_tolerance, cg_max_iter, scheduler, verbose)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_cholesky_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_cholesky\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcg_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcg_tolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_cg_iterations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcg_max_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             loss = 0.5 * sum([torch.dot(model.train_targets, precision_operator.matmul(model.train_targets.view(-1, 1)).squeeze()),\n\u001b[0;32m---> 66\u001b[0;31m                               \u001b[0;34m-\u001b[0m\u001b[0mprecision_operator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                               model.train_targets.shape[0] * math.log(2 * math.pi)])\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# add log probs of priors on the (functions of) parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py\u001b[0m in \u001b[0;36minv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvQuadLogdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m         inv_quad_term, pinvk_logdet = func(\n\u001b[0m\u001b[1;32m   1765\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mprecond_lt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/linear_operator/functions/_inv_quad_logdet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, representation_tree, precond_representation_tree, preconditioner, num_precond_args, inv_quad, probe_vectors, probe_vector_norms, *args)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Perform solves (for inv_quad) and tridiagonalization (for estimating logdet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mrhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msolves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tridiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_random_probes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Final values to return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, rhs, preconditioner, num_tridiag)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[0mTODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \"\"\"\n\u001b[0;32m--> 789\u001b[0;31m         return utils.linear_cg(\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py\u001b[0m in \u001b[0;36mlinear_cg\u001b[0;34m(matmul_closure, rhs, n_tridiag, tolerance, eps, stop_updating_after, max_iter, max_tridiag_iter, initial_guess, preconditioner)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Get next alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# alpha_{k} = (residual_{k-1}^T precon_residual{k-1}) / (p_vec_{k-1}^T mat p_vec_{k-1})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mmvms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_conjugate_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprecond\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_conjugate_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmul_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/manifold_gp/operators/noise_wrapper_operator.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/manifold_gp/operators/scale_wrapper_operator.py\u001b[0m in \u001b[0;36m_matmul\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_scale\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if load_manifold_model:\n",
    "    model.load_state_dict(torch.load('../models/srmnist_manifold_semisupervised.pth' if single_digit else '../models/rmnist_manifold_semisupervised.pth'))\n",
    "\n",
    "if train_manifold_model:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-2, weight_decay=0.0)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50, threshold=1e-3, threshold_mode='rel',\n",
    "                                                           cooldown=0, min_lr=0, eps=1e-8, verbose=True)\n",
    "    loss = manifold_informed_train(model, optimizer, max_iter=100, tolerance=1e-2, update_norm=None, num_rand_vec=100,\n",
    "                                   max_cholesky=1000, cg_tolerance=1e-2, cg_max_iter=1000, scheduler=scheduler, verbose=True)\n",
    "    if save_manifold_model:\n",
    "        torch.save(model.state_dict(), '../models/srmnist_manifold_semisupervised.pth' if single_digit else '../models/rmnist_manifold_semisupervised.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cce5132-05ac-4ef5-a6c8-e2aab55c867f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Loss: -0.067, Lr: 0.1,\tNoise Variance: 0.009,\tSignal Variance: 0.938,\tLengthscale: 1.064\n",
      "Iteration: 1, Loss: -0.140, Lr: 0.1,\tNoise Variance: 0.008,\tSignal Variance: 0.878,\tLengthscale: 1.131\n",
      "Iteration: 2, Loss: -0.241, Lr: 0.1,\tNoise Variance: 0.007,\tSignal Variance: 0.821,\tLengthscale: 1.200\n",
      "Iteration: 3, Loss: -0.301, Lr: 0.1,\tNoise Variance: 0.007,\tSignal Variance: 0.767,\tLengthscale: 1.270\n",
      "Iteration: 4, Loss: -0.355, Lr: 0.1,\tNoise Variance: 0.006,\tSignal Variance: 0.716,\tLengthscale: 1.342\n",
      "Iteration: 5, Loss: -0.415, Lr: 0.1,\tNoise Variance: 0.006,\tSignal Variance: 0.667,\tLengthscale: 1.416\n",
      "Iteration: 6, Loss: -0.480, Lr: 0.1,\tNoise Variance: 0.005,\tSignal Variance: 0.620,\tLengthscale: 1.492\n",
      "Iteration: 7, Loss: -0.541, Lr: 0.1,\tNoise Variance: 0.005,\tSignal Variance: 0.577,\tLengthscale: 1.568\n",
      "Iteration: 8, Loss: -0.612, Lr: 0.1,\tNoise Variance: 0.004,\tSignal Variance: 0.537,\tLengthscale: 1.646\n",
      "Iteration: 9, Loss: -0.685, Lr: 0.1,\tNoise Variance: 0.004,\tSignal Variance: 0.499,\tLengthscale: 1.725\n",
      "Iteration: 10, Loss: -0.806, Lr: 0.1,\tNoise Variance: 0.003,\tSignal Variance: 0.465,\tLengthscale: 1.804\n",
      "Iteration: 11, Loss: -0.820, Lr: 0.1,\tNoise Variance: 0.003,\tSignal Variance: 0.435,\tLengthscale: 1.884\n",
      "Iteration: 12, Loss: -0.891, Lr: 0.1,\tNoise Variance: 0.003,\tSignal Variance: 0.407,\tLengthscale: 1.964\n",
      "Iteration: 13, Loss: -0.941, Lr: 0.1,\tNoise Variance: 0.003,\tSignal Variance: 0.382,\tLengthscale: 2.044\n",
      "Iteration: 14, Loss: -1.011, Lr: 0.1,\tNoise Variance: 0.002,\tSignal Variance: 0.360,\tLengthscale: 2.125\n",
      "Iteration: 15, Loss: -1.069, Lr: 0.1,\tNoise Variance: 0.002,\tSignal Variance: 0.341,\tLengthscale: 2.206\n",
      "Iteration: 16, Loss: -1.114, Lr: 0.1,\tNoise Variance: 0.002,\tSignal Variance: 0.324,\tLengthscale: 2.287\n",
      "Iteration: 17, Loss: -1.160, Lr: 0.1,\tNoise Variance: 0.002,\tSignal Variance: 0.311,\tLengthscale: 2.368\n",
      "Iteration: 18, Loss: -1.196, Lr: 0.1,\tNoise Variance: 0.002,\tSignal Variance: 0.299,\tLengthscale: 2.449\n",
      "Iteration: 19, Loss: -1.296, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.290,\tLengthscale: 2.529\n",
      "Iteration: 20, Loss: -1.331, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.284,\tLengthscale: 2.609\n",
      "Iteration: 21, Loss: -1.330, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.279,\tLengthscale: 2.689\n",
      "Iteration: 22, Loss: -1.395, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.275,\tLengthscale: 2.768\n",
      "Iteration: 23, Loss: -1.445, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.273,\tLengthscale: 2.846\n",
      "Iteration: 24, Loss: -1.481, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.272,\tLengthscale: 2.924\n",
      "Iteration: 25, Loss: -1.486, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.272,\tLengthscale: 3.002\n",
      "Iteration: 26, Loss: -1.542, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.272,\tLengthscale: 3.078\n",
      "Iteration: 27, Loss: -1.563, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.272,\tLengthscale: 3.154\n",
      "Iteration: 28, Loss: -1.593, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.273,\tLengthscale: 3.230\n",
      "Iteration: 29, Loss: -1.633, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.273,\tLengthscale: 3.304\n",
      "Iteration: 30, Loss: -1.672, Lr: 0.1,\tNoise Variance: 0.001,\tSignal Variance: 0.273,\tLengthscale: 3.378\n",
      "Iteration: 31, Loss: -1.661, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.274,\tLengthscale: 3.450\n",
      "Iteration: 32, Loss: -1.669, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.273,\tLengthscale: 3.522\n",
      "Iteration: 33, Loss: -1.714, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.272,\tLengthscale: 3.592\n",
      "Iteration: 34, Loss: -1.705, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.270,\tLengthscale: 3.661\n",
      "Iteration: 35, Loss: -1.748, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.268,\tLengthscale: 3.730\n",
      "Iteration: 36, Loss: -1.738, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.265,\tLengthscale: 3.796\n",
      "Iteration: 37, Loss: -1.769, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.261,\tLengthscale: 3.862\n",
      "Iteration: 38, Loss: -1.746, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.257,\tLengthscale: 3.927\n",
      "Iteration: 39, Loss: -1.794, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.253,\tLengthscale: 3.991\n",
      "Iteration: 40, Loss: -1.769, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.249,\tLengthscale: 4.054\n",
      "Iteration: 41, Loss: -1.787, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.244,\tLengthscale: 4.115\n",
      "Iteration: 42, Loss: -1.799, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.240,\tLengthscale: 4.176\n",
      "Iteration: 43, Loss: -1.807, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.235,\tLengthscale: 4.235\n",
      "Iteration: 44, Loss: -1.825, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.231,\tLengthscale: 4.293\n",
      "Iteration: 45, Loss: -1.829, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.227,\tLengthscale: 4.350\n",
      "Iteration: 46, Loss: -1.867, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.224,\tLengthscale: 4.406\n",
      "Iteration: 47, Loss: -1.837, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.221,\tLengthscale: 4.460\n",
      "Iteration: 48, Loss: -1.880, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.219,\tLengthscale: 4.514\n",
      "Iteration: 49, Loss: -1.905, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.217,\tLengthscale: 4.566\n",
      "Iteration: 50, Loss: -1.944, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.216,\tLengthscale: 4.618\n",
      "Iteration: 51, Loss: -1.895, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.216,\tLengthscale: 4.668\n",
      "Iteration: 52, Loss: -1.940, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.217,\tLengthscale: 4.718\n",
      "Iteration: 53, Loss: -1.899, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.219,\tLengthscale: 4.767\n",
      "Iteration: 54, Loss: -1.900, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.221,\tLengthscale: 4.814\n",
      "Iteration: 55, Loss: -1.917, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.223,\tLengthscale: 4.860\n",
      "Iteration: 56, Loss: -1.881, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.225,\tLengthscale: 4.904\n",
      "Iteration: 57, Loss: -1.907, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.228,\tLengthscale: 4.948\n",
      "Iteration: 58, Loss: -1.954, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.231,\tLengthscale: 4.990\n",
      "Iteration: 59, Loss: -1.960, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.235,\tLengthscale: 5.031\n",
      "Iteration: 60, Loss: -1.902, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.239,\tLengthscale: 5.072\n",
      "Iteration: 61, Loss: -1.907, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.242,\tLengthscale: 5.111\n",
      "Iteration: 62, Loss: -1.909, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.246,\tLengthscale: 5.150\n",
      "Iteration: 63, Loss: -1.916, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.249,\tLengthscale: 5.188\n",
      "Iteration: 64, Loss: -1.899, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.253,\tLengthscale: 5.225\n",
      "Iteration: 65, Loss: -1.922, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.255,\tLengthscale: 5.260\n",
      "Iteration: 66, Loss: -1.907, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.258,\tLengthscale: 5.296\n",
      "Iteration: 67, Loss: -1.880, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.260,\tLengthscale: 5.331\n",
      "Iteration: 68, Loss: -1.894, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.261,\tLengthscale: 5.366\n",
      "Iteration: 69, Loss: -1.898, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.262,\tLengthscale: 5.400\n",
      "Iteration: 70, Loss: -1.865, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.263,\tLengthscale: 5.434\n",
      "Iteration: 71, Loss: -1.880, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.263,\tLengthscale: 5.468\n",
      "Iteration: 72, Loss: -1.898, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.263,\tLengthscale: 5.501\n",
      "Iteration: 73, Loss: -1.937, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.263,\tLengthscale: 5.533\n",
      "Iteration: 74, Loss: -1.896, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.263,\tLengthscale: 5.565\n",
      "Iteration: 75, Loss: -1.932, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.264,\tLengthscale: 5.596\n",
      "Iteration: 76, Loss: -1.897, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.265,\tLengthscale: 5.626\n",
      "Iteration: 77, Loss: -1.892, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.266,\tLengthscale: 5.656\n",
      "Iteration: 78, Loss: -1.898, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.267,\tLengthscale: 5.685\n",
      "Iteration: 79, Loss: -1.898, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.268,\tLengthscale: 5.714\n",
      "Iteration: 80, Loss: -1.860, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.269,\tLengthscale: 5.742\n",
      "Iteration: 81, Loss: -1.908, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.270,\tLengthscale: 5.770\n",
      "Iteration: 82, Loss: -1.852, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.271,\tLengthscale: 5.797\n",
      "Iteration: 83, Loss: -1.881, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.272,\tLengthscale: 5.824\n",
      "Iteration: 84, Loss: -1.911, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.274,\tLengthscale: 5.853\n",
      "Iteration: 85, Loss: -1.865, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.276,\tLengthscale: 5.880\n",
      "Iteration: 86, Loss: -1.861, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.278,\tLengthscale: 5.906\n",
      "Iteration: 87, Loss: -1.900, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.281,\tLengthscale: 5.931\n",
      "Iteration: 88, Loss: -1.841, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.283,\tLengthscale: 5.956\n",
      "Iteration: 89, Loss: -1.883, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.285,\tLengthscale: 5.979\n",
      "Iteration: 90, Loss: -1.905, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.288,\tLengthscale: 6.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.013912507332861423 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.014273851178586483 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 91, Loss: -1.878, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.290,\tLengthscale: 6.027\n",
      "Iteration: 92, Loss: -1.892, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.293,\tLengthscale: 6.050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.01394312921911478 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.011672121472656727 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 93, Loss: -1.875, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.296,\tLengthscale: 6.073\n",
      "Iteration: 94, Loss: -1.869, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.298,\tLengthscale: 6.097\n",
      "Iteration: 95, Loss: -1.847, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.300,\tLengthscale: 6.121\n",
      "Iteration: 96, Loss: -1.868, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.302,\tLengthscale: 6.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.011595646850764751 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.012011639773845673 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 97, Loss: -1.845, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.303,\tLengthscale: 6.170\n",
      "Iteration: 98, Loss: -1.870, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.305,\tLengthscale: 6.194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.014803348109126091 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n",
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.018397025763988495 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 99, Loss: -1.826, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.306,\tLengthscale: 6.219\n",
      "Iteration: 100, Loss: -1.866, Lr: 0.1,\tNoise Variance: 0.000,\tSignal Variance: 0.308,\tLengthscale: 6.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bernardo/.local/lib/python3.10/site-packages/linear_operator/utils/linear_cg.py:338: NumericalWarning: CG terminated in 1000 iterations with average residual norm 0.0153274517506361 which is larger than the tolerance of 0.01 specified by linear_operator.settings.cg_tolerance. If performance is affected, consider raising the maximum number of CG iterations by running code in a linear_operator.settings.max_cg_iterations(value) context.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if load_vanilla_model:\n",
    "    model_vanilla.load_state_dict(torch.load('../models/srmnist_vanilla_semisupervised.pth' if single_digit else '../models/rmnist_vanilla_semisupervised.pth'))\n",
    "\n",
    "if train_vanilla_model:\n",
    "    optimizer_vanilla = torch.optim.Adam(model_vanilla.parameters(), lr=1e-1, weight_decay=0.0)\n",
    "    scheduler_vanilla = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_vanilla, mode='min', factor=0.5, patience=200, threshold=1e-3, \n",
    "                                                                   threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-8, verbose=False)\n",
    "    loss = vanilla_train(model_vanilla, optimizer_vanilla, max_iter=100, max_cholesky=1000, tolerance=1e-2, cg_tolerance=1e-2, cg_max_iter=1000, scheduler=None, \n",
    "                  verbose=True)\n",
    "    if save_vanilla_model:\n",
    "        torch.save(model_vanilla.state_dict(), '../models/srmnist_vanilla_semisupervised.pth' if single_digit else '../models/rmnist_vanilla_semisupervised.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab36075",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83bd90e4-42d9-4b81-8fc2-e553a99c5a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Vanilla:  tensor(0.0132, device='cuda:0')\n",
      "NLL Vanilla:  tensor(-2.9825, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "rmse_vanilla, nll_vanilla = test_model(model_vanilla, test_x, test_y, noisy_test=True, base_model=None, max_cholesky=1000, cg_tolerance=1e-2, cg_iterations=1000)\n",
    "print(\"RMSE Vanilla: \", rmse_vanilla)\n",
    "print(\"NLL Vanilla: \", nll_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f37f4400-cfa1-4541-bf26-f4289e5747ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Geometric:  tensor(0.1024, device='cuda:0')\n",
      "NLL Geometric:  tensor(-0.8141, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "rmse, nll = test_model(model, test_x, test_y, noisy_test=True, base_model=model_vanilla, max_cholesky=1000, cg_tolerance=1e-2, cg_iterations=2000)\n",
    "print(\"RMSE Geometric: \", rmse)\n",
    "print(\"NLL Geometric: \", nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddfda47-a247-4171-bf07-c088d9fd3827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
